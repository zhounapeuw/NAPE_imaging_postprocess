{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPE Calcium Imaging Event-Related Analysis\n",
    "\n",
    "## What does this script do:\n",
    "\n",
    "Loads activity traces from ROIs/sources across the whole session as well as timing of behavioral/manipulation evetns, then extracts a window of activity around each event, and finally generates numerous event-related plots resolving and averaging across trials and ROIs.\n",
    "\n",
    "How to run this code\n",
    "------------------------------------\n",
    "\n",
    "In this jupyter notebook, First find the code block with the comment header called USER-DEFINED VARIABLES. Edit the variables according to your data and output preferences. Then just run all cells in order (shift + enter; or in the dropdown menu: Kernel->Resart & Run All). Please make sure you set the correct sampling rate (fs) in the user-defined variables block of code.\n",
    "\n",
    "### Required Prerequisite/Input Files\n",
    "\n",
    "All data should reside in a parent folder. This folder's name should be the name of the session and ideally be the same as the base name of the recording file.\n",
    "\n",
    "1. ROI/source activity signals file ( `fparams['fname_signal']` ): This is either a npy or CSV file where rows are individual ROIs/sources and columns are samples, and the values are activity levels (ie. fluorescence or voltage for ephys). Note the CSV should not \n",
    "2. Event occurrence file (`fparams['fname_events']` ): This is either a pickle file or a CSV file. For the pickle file, it should contain a python dictionary where keys are event condition names and associated values are lists that contain event occurrence times (in samples). If using a CSV, the data should be in tidy format formated like what is shown here (note currently the first row, first and second columns should be \"event\" and \"sample\" respectively: https://github.com/zhounapeuw/NAPE_imaging_postprocess/raw/main/docs/_images/napeca_post_event_csv_format.png\n",
    "\n",
    "\n",
    "Required Packages\n",
    "-----------------\n",
    "Python 3.7, seaborn, matplotlib, pandas, scikit-learn\n",
    "\n",
    "Custom code requirements: utils\n",
    "\n",
    "User-Defined Parameters \n",
    "----------\n",
    "\n",
    "fname_signal : string\n",
    "    \n",
    "    Name of file that contains roi activity traces. Must include full file name with extension. Accepted file types: .npy, .csv. IMPORTANT: data dimensions should be rois (y) by samples/time (x)\n",
    "\n",
    "fname_events : string\n",
    "\n",
    "    Name of file that contains event occurrences. Must include full file name with extension. Accepted file types: .pkl, .csv. Pickle (pkl) files need to contain a dictionary where keys are the condition names and the values are lists containing samples/frames for each corresponding event. Csv's should have two columns (event condition, sample). The first row are the column names. Subsequent rows contain each trial's event condition and sample in tidy format. See example in sample_data folder for formatting, or this link: https://github.com/zhounapeuw/NAPE_imaging_postprocess/raw/main/docs/_images/napeca_post_event_csv_format.png\n",
    "\n",
    "fdir : string \n",
    "\n",
    "    Root file directory containing the raw tif, tiff, h5 files. IMPORTANT Note: leave off the last backslash, and include the letter r in front of string (treats the contents as a raw string). For example: r'C:\\Users\\my_user\\analyze_sessions'\n",
    "\n",
    "fname : string\n",
    "\n",
    "    Session name; by default this is the name of the parent folder that the data resides in, but can be changed by user to be any string. This fname variable is mainly used to name the saved output files.\n",
    "\n",
    "flag_save_figs : boolean  \n",
    "\n",
    "    Set as True to save figures as JPG and vectorized formats.  \n",
    "    \n",
    "fs : float\n",
    "\n",
    "    Sampling rate of imaging data. It is imperative that this value is correct; otherwise the incorrect time windows will be pulled out for each event. If you suspect that \n",
    "    the sampling rate (fs) was not set correctly in the NAPECA preprocessing pipeline, go into the saved json file and edit the fs value.\n",
    "    \n",
    "selected_conditions : list of strings\n",
    "\n",
    "    Specific conditions that the user wants to analyze; needs to be exactly the name of conditions in the events CSV or pickle file\n",
    "\n",
    "trial_start_end : list of two entries  \n",
    "\n",
    "    Entries can be ints or floats. The first entry is the time in seconds relative to the event/ttl onset for the start of the event analysis window (negative if before the event/ttl onset. The second entry is the time in seconds for the end of the event analysis window. For example if the desired analysis window is 5.5 seconds before event onset and 8 seconds after, `trial_start_end` would be [-5.5, 8].  \n",
    "    \n",
    "baseline_end : int/float  \n",
    "\n",
    "    Time in seconds for the end of the baseline epoch. By default, the baseline epoch start time will be the first entry ot `trial_start_end`. This baseline epoch is used for calculating baseline normalization metrics.\n",
    "    \n",
    "event_dur : int/float  \n",
    "\n",
    "    Time in seconds representing how long the behavioral event or stimulation, etc. lasts. A green line with the corresponding length will be plotted indicating stimulus duration\n",
    "\n",
    "event_sort_analysis_win : list with two float entries\n",
    "\n",
    "    Time window [a, b] in seconds during which some visualization calculations will apply to. For example, if the user sets flag_sort_rois to be True, ROIs in heatmaps will be sorted based on the mean activity in the time window between a and b. Similar principle holds for the time-averaged barplots.\n",
    "\n",
    "opto_blank_frame : boolean\n",
    "\n",
    "    if PMTs were blanked during stim, use detected stim times (from preprocessing) to set those frames to NaN\n",
    "\n",
    "flag_npil_corr : boolean  \n",
    "\n",
    "    Set as True if user would like to load in neuropil corrected data from the preprocessing pipeline. Must have a \\*\\_neuropil\\_corrected_signal_* file in the directory. If set as False, just use the extracted_signal file.\n",
    "    \n",
    "flag_zscore : boolean  \n",
    "\n",
    "    Set as True if analyzed data should be baseline z-scored on a trial level.  \n",
    "\n",
    "flag_sort_rois : boolean\n",
    "\n",
    "    Set as True to sort ROIs on the y axis of heatmaps. This works with `user_sort_method` and `roi_sort_cond` for specifying details of sorting.\n",
    "\n",
    "user_sort_method : string\n",
    "    \n",
    "    Set to 'peak_time' to sort ROIs by peak time during event_sort_dur; 'max_value' to sort by max value\n",
    "    \n",
    "roi_sort_cond : string\n",
    "    \n",
    "    Condition to perform sorting on\n",
    "\n",
    "flag_roi_trial_avg_errbar : boolean  \n",
    "\n",
    "    Set as True to set standard error of mean shaded portions for line plots of trial-averaged activity.   \n",
    "\n",
    "flag_trial_avg_errbar : boolean\n",
    "\n",
    "    toggle standard error bars on trial-averaged data\n",
    "\n",
    "interesting_rois : list of ints  \n",
    "\n",
    "    All entries are indices for ROIs that will be marked in heatmaps by arrows.  \n",
    "\n",
    "Optional Parameters (Only relevant if using batch_process)\n",
    "-------------------\n",
    "\n",
    "user_sort_method : string\n",
    "    \n",
    "    Takes the strings 'peak_time' or 'max_value'\n",
    "    \n",
    "    \n",
    "roi_sort_cond : string\n",
    "    for roi-resolved heatmaps, which condition to sort ROIs by\n",
    "    \n",
    "    Defaults to first condition available\n",
    "    \n",
    "Output\n",
    "-------\n",
    "\n",
    "event_rel_analysis : folder containing plots in jpg/png and vectorized formats\n",
    "\n",
    "events_dict.pkl : pickle file containing a dictionary containing event-triggered data from each cell and organized by event condition. Raw and z-scored data are included as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#important for text to be detected when importing saved figures into illustrator\n",
    "matplotlib.rcParams['pdf.fonttype']=42\n",
    "matplotlib.rcParams['ps.fonttype']=42\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple class to update limits as you go through iterations of data\n",
    "# first call update_lims(first_lims)\n",
    "# then update_lims.update(new_lims)\n",
    "# update_lims.output() outputs lims\n",
    "class update_lims:\n",
    "    \n",
    "    def __init__(self, lims):\n",
    "        self.lims = lims\n",
    "        \n",
    "    \n",
    "    def update(self, new_lims):\n",
    "        if self.lims[0] > new_lims[0]:\n",
    "            self.lims[0] = new_lims[0]\n",
    "        \n",
    "        if self.lims[1] < new_lims[1]:\n",
    "            self.lims[1] = new_lims[1]\n",
    "\n",
    "    def output(self):\n",
    "        return self.lims\n",
    "    \n",
    "    \n",
    "# find 2D subplot index based on a numerical incremented index (ie. idx=3 would be (2,1) for a 2x2 subplot figure)     \n",
    "def subplot_loc(idx, num_rows, num_col):\n",
    "    if n_rows == 1:\n",
    "        subplot_index = idx\n",
    "    else:\n",
    "        subplot_index = np.unravel_index(idx, (n_rows, int(n_columns))) # turn int index to a tuple of array coordinates\n",
    "    return subplot_index\n",
    "\n",
    "\n",
    "def get_cmap(n, name='plasma'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "\n",
    "def is_all_nans(vector):\n",
    "    \"\"\"\n",
    "    checks if series or vector contains all nans; returns boolean. Used to identify and exclude all-nan rois\n",
    "    \"\"\"\n",
    "    if isinstance(vector, pd.Series):\n",
    "        vector = vector.values\n",
    "    return np.isnan(vector).all()\n",
    "\n",
    "# declare some fixed constant variables\n",
    "axis_label_size = 15\n",
    "tick_font_size = 14 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "USER-DEFINED VARIABLES\n",
    "\"\"\"\n",
    "\n",
    "def define_params(method = 'single'):\n",
    "    \n",
    "    fparams = {}\n",
    "    \n",
    "    if method == 'single':\n",
    "        \n",
    "        fparams['fname_signal'] = 'VJ_OFCVTA_7_260_D6_neuropil_corrected_signals_15_50_beta_0.8.npy'   # \n",
    "        fparams['fname_events'] = 'event_times_VJ_OFCVTA_7_260_D6_trained.csv'\n",
    "        # for your own data, modify and use this phrase below for fparams['fname']: \n",
    "        # r'C:\\Users\\stuberadmin\\Documents\\GitHub\\NAPE_imaging_postprocess\\napeca_post\\sample_data' \n",
    "        # replace the contents inside the apostrophes with the path to your data; make sure the r comes before the apostrophe\n",
    "        fparams['fdir'] = os.path.abspath('./sample_data/VJ_OFCVTA_7_260_D6') \n",
    "        fparams['fname'] = os.path.split(fparams['fdir'])[1]\n",
    "        fparams['flag_save_figs'] = False\n",
    "        \n",
    "        # set the sampling rate\n",
    "        fparams['fs'] = 5 # this gets overwritten by json fs variable (if it exists) that is saved in preprocessing\n",
    "        json_fpath = os.path.join(fparams['fdir'], fparams['fname']+\".json\")\n",
    "        if os.path.exists(json_fpath):\n",
    "            json_data = utils.open_json(json_fpath)\n",
    "            if 'fs' in json_data:\n",
    "                fparams['fs'] = json_data['fs']\n",
    "\n",
    "        fparams['selected_conditions'] = None # set to None if want to include all conditions from behav data\n",
    "        \n",
    "        # trial windowing and normalization\n",
    "        fparams['trial_start_end'] = [-2, 8] # [start, end] times (in seconds) included in the visualization \n",
    "        fparams['flag_zscore'] = True # whether or not to z-score data for plots\n",
    "        fparams['baseline_end'] = -0.2 # baseline epoch end time (in seconds) for performing baseline normalization\n",
    "        fparams['event_dur'] = 2 # duration of stim/event in seconds; displays a line below main plot indicating event duration\n",
    "        fparams['event_sort_analysis_win'] = [0, 5] # time window (in seconds)\n",
    "        \n",
    "        # session info\n",
    "        fparams['opto_blank_frame'] = False # if PMTs were blanked during stim, set stim times to nan (instead of 0)\n",
    "\n",
    "        # ROI sorting; if flag_sort_rois is set to True, ROIs are sorted by activity in the fparams['event_sort_analysis_win'] window\n",
    "        fparams['flag_sort_rois'] = True\n",
    "        if fparams['flag_sort_rois']:\n",
    "            \n",
    "            fparams['user_sort_method'] = 'max_value' # peak_time or max_value\n",
    "            fparams['roi_sort_cond'] = 'plus' # for roi-resolved heatmaps, which condition to sort ROIs by\n",
    "            \n",
    "        # errorbar and saving figures\n",
    "        fparams['flag_roi_trial_avg_errbar'] = True # toggle to show error bar on roi- and trial-averaged traces\n",
    "        fparams['flag_trial_avg_errbar'] = True # toggle to show error bars on the trial-avg traces\n",
    "        fparams['interesting_rois'] = [] #[ 0, 1, 2, 23, 22, 11, 9, 5, 6, 7, 3, 4, 8, 12, 14, 15, 16, 17] # [35, 30, 20, 4] #\n",
    "    \n",
    "    elif method == 'f2a': # if string is empty, load predefined list of files in files_to_analyze_event\n",
    "        \n",
    "        #the files_to_anaylize_event method does not seem to exist\n",
    "        fparams = files_to_analyze_event.define_fparams()\n",
    "\n",
    "    elif method == 'root_dir':\n",
    "        \n",
    "        pass\n",
    "\n",
    "    with open(os.path.join(fparams['fdir'], 'event_analysis_fparam.json'), 'w') as fp:\n",
    "        json.dump(fparams, fp)\n",
    "    \n",
    "    return fparams\n",
    "\n",
    "fparams = define_params(method = 'single') # options are 'single', 'f2a', 'root_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare paths\n",
    "signals_fpath = os.path.join(fparams['fdir'], fparams['fname_signal'])\n",
    "events_file_path = os.path.join(fparams['fdir'], fparams['fname_events'])\n",
    "\n",
    "save_dir = os.path.join(fparams['fdir'], 'event_rel_analysis')\n",
    "\n",
    "utils.check_exist_dir(save_dir); # make the save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declare_paths(fparams):\n",
    "    paths = {}\n",
    "    paths['signals_fpath'] = os.path.join(fparams['fdir'], fparams['fname_signal'])\n",
    "    paths['events_file_path'] = os.path.join(fparams['fdir'], fparams['fname_events'])\n",
    "    paths['save_dir'] = os.path.join(fparams['fdir'], 'event_rel_analysis')\n",
    "    \n",
    "    utils.check_exist_dir(paths['save_dir'])\n",
    "\n",
    "    return paths\n",
    "\n",
    "paths = declare_paths(fparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create variables that reference samples and times for slicing and plotting the data\n",
    "\n",
    "trial_start_end_sec = np.array(fparams['trial_start_end']) # trial windowing in seconds relative to ttl-onset/trial-onset, in seconds\n",
    "baseline_start_end_sec = np.array([trial_start_end_sec[0], fparams['baseline_end']])\n",
    "\n",
    "# convert times to samples and get sample vector for the trial \n",
    "trial_begEnd_samp = trial_start_end_sec*fparams['fs'] # turn trial start/end times to samples\n",
    "trial_svec = np.arange(trial_begEnd_samp[0], trial_begEnd_samp[1])\n",
    "# and for baseline period\n",
    "baseline_begEnd_samp = baseline_start_end_sec*fparams['fs']\n",
    "baseline_svec = (np.arange(baseline_begEnd_samp[0], baseline_begEnd_samp[1]+1, 1) - baseline_begEnd_samp[0]).astype('int')\n",
    "\n",
    "# calculate time vector for plot x axes\n",
    "num_samples_trial = len( trial_svec )\n",
    "tvec = np.round(np.linspace(trial_start_end_sec[0], trial_start_end_sec[1], num_samples_trial+1), 2)\n",
    "\n",
    "# find samples and calculations for time 0 for plotting\n",
    "t0_sample = utils.get_tvec_sample(tvec, 0) # grabs the sample index of a given time from a vector of times\n",
    "event_end_sample = int(np.round(t0_sample+fparams['event_dur']*fparams['fs']))\n",
    "event_bound_ratio = [(t0_sample)/num_samples_trial , event_end_sample/num_samples_trial] # fraction of total samples for event start and end; only used for plotting line indicating event duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_timing(fparams):\n",
    "    event_data = {}\n",
    "\n",
    "    event_data['trial_start_end_sec'] = np.array(fparams['trial_start_end'])\n",
    "    event_data['baseline_start_end_sec'] = np.array([event_data['trial_start_end_sec'][0], fparams['baseline_end']])\n",
    "\n",
    "    event_data['trial_begEnd_samp'] = event_data['trial_start_end_sec']*fparams['fs']\n",
    "    event_data['trial_svec'] = np.arange(event_data['trial_begEnd_samp'][0], event_data['trial_begEnd_samp'][1])\n",
    "\n",
    "    event_data['baseline_begEnd_samp'] = event_data['baseline_start_end_sec']*fparams['fs']\n",
    "    event_data['baseline_svec'] = (np.arange(event_data['baseline_begEnd_samp'][0], event_data['baseline_begEnd_samp'][1]+1, 1) - event_data['baseline_begEnd_samp'][0]).astype('int') \n",
    "\n",
    "    event_data['num_samples_trial'] = len( event_data['trial_svec'] )\n",
    "    event_data['tvec'] = np.round(np.linspace(event_data['trial_start_end_sec'][0], event_data['trial_start_end_sec'][1], event_data['num_samples_trial']+1), 2)\n",
    "\n",
    "    event_data['t0_sample'] = utils.get_tvec_sample(event_data['tvec'], 0)\n",
    "    event_data['event_end_sample'] = int(np.round(event_data['t0_sample']+fparams['event_dur']*fparams['fs']))\n",
    "    event_data['event_bound_ratio'] = [(event_data['t0_sample'])/event_data['num_samples_trial'] , event_data['event_end_sample']/event_data['num_samples_trial']]\n",
    "\n",
    "    return event_data\n",
    "\n",
    "event_data = event_timing(fparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signals = utils.load_signals(signals_fpath)\n",
    "\n",
    "num_rois = signals.shape[0]\n",
    "all_nan_rois = np.where(np.apply_along_axis(is_all_nans, 1, signals)) # find rois with activity as all nans\n",
    "\n",
    "# if opto stim frames were detected in preprocessing, set these frames to be NaN (b/c of stim artifact)\n",
    "if fparams['opto_blank_frame']:\n",
    "    try:\n",
    "        glob_stim_files = glob.glob(os.path.join(fparams['fdir'], \"{}*_stimmed_frames.pkl\".format(fparams['fname'])))\n",
    "        stim_frames = pickle.load( open( glob_stim_files[0], \"rb\" ) )\n",
    "        signals[:,stim_frames['samples']] = None # blank out stimmed frames\n",
    "        flag_stim = True\n",
    "        print('Detected stim data; replaced stim samples with NaNs')\n",
    "    except:\n",
    "        flag_stim = False\n",
    "        print('Note: No stim preprocessed meta data detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_differentiation(fparams, paths):\n",
    "    roi_info = {}\n",
    "\n",
    "    roi_info['signals'] = utils.load_signals(paths['signals_fpath'])\n",
    "\n",
    "    roi_info['num_rois'] = roi_info['signals'].shape[0]\n",
    "    roi_info['all_nan_rois'] = np.where(np.apply_along_axis(is_all_nans, 1, roi_info['signals'])) # find rois with activity as all nans\n",
    "\n",
    "    # if opto stim frames were detected in preprocessing, set these frames to be NaN (b/c of stim artifact)\n",
    "    if fparams['opto_blank_frame']:\n",
    "        try:\n",
    "            glob_stim_files = glob.glob(os.path.join(fparams['fdir'], \"{}*_stimmed_frames.pkl\".format(fparams['fname'])))\n",
    "            stim_frames = pickle.load( open( glob_stim_files[0], \"rb\" ) )\n",
    "            roi_info['signals'][:,stim_frames['samples']] = None # blank out stimmed frames\n",
    "            flag_stim = True\n",
    "            print('Detected stim data; replaced stim samples with NaNs')\n",
    "        except:\n",
    "            flag_stim = False\n",
    "            print('Note: No stim preprocessed meta data detected.')\n",
    "\n",
    "    return roi_info\n",
    "    \n",
    "roi_info = roi_differentiation(fparams, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load behavioral data and trial info\n",
    "try:\n",
    "    glob_event_files = glob.glob(events_file_path) # look for a file in specified directory\n",
    "    if 'csv' in glob_event_files[0]:\n",
    "        event_times = utils.df_to_dict(glob_event_files[0])\n",
    "    elif 'pkl' in glob_event_files[0]:\n",
    "        event_times = pickle.load( open( glob_event_files[0], \"rb\" ), fix_imports=True, encoding='latin1' ) # latin1 b/c original pickle made in python 2\n",
    "    event_frames = utils.dict_samples_to_time(event_times, fparams['fs'])\n",
    "except:\n",
    "    print('Cannot find behavioral data file or file path is incorrect; utils.extract_trial_data will throw error.')\n",
    "\n",
    "# identify conditions to analyze\n",
    "all_conditions = event_frames.keys()\n",
    "conditions = [ condition for condition in all_conditions if len(event_frames[condition]) > 0 ] # keep conditions that have events\n",
    "\n",
    "conditions.sort()\n",
    "if fparams['selected_conditions']:\n",
    "    conditions = fparams['selected_conditions']\n",
    "\n",
    "cmap_lines = get_cmap(len(conditions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_behavioral_data(fparams, paths):\n",
    "    behav_data = {}\n",
    "\n",
    "    try:\n",
    "        glob_event_files = glob.glob(paths['events_file_path']) # look for a file in specified directory\n",
    "        if 'csv' in glob_event_files[0]:\n",
    "            event_times = utils.df_to_dict(glob_event_files[0])\n",
    "        elif 'pkl' in glob_event_files[0]:\n",
    "            event_times = pickle.load( open( glob_event_files[0], \"rb\" ), fix_imports=True, encoding='latin1' ) # latin1 b/c original pickle made in python 2\n",
    "        behav_data['event_frames'] = utils.dict_samples_to_time(event_times, fparams['fs'])\n",
    "    except:\n",
    "        print('Cannot find behavioral data file or file path is incorrect; utils.extract_trial_data will throw error.')\n",
    "\n",
    "    # identify conditions to analyze\n",
    "    all_conditions = behav_data['event_frames'].keys()\n",
    "    behav_data['conditions'] = [ condition for condition in all_conditions if len(behav_data['event_frames'][condition]) > 0 ] # keep conditions that have events\n",
    "\n",
    "    behav_data['conditions'].sort()\n",
    "    if fparams['selected_conditions']:\n",
    "        behav_data['conditions'] = fparams['selected_conditions']\n",
    "\n",
    "    behav_data['cmap_lines'] = get_cmap(len(behav_data['conditions']))\n",
    "\n",
    "behav_data = load_behavioral_data(fparams, paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start trial-based preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MAIN data processing function to extract event-centered data\n",
    "\n",
    "extract and save trial data, \n",
    "saved data are in the event_rel_analysis subfolder, a pickle file that contains the extracted trial data\n",
    "\"\"\"\n",
    "data_dict = utils.extract_trial_data(roi_info['signals'],  event_data['tvec'],  event_data['trial_begEnd_samp'],  event_data['event_frames'], \n",
    "                                     behav_data['conditions'], baseline_start_end_samp =  event_data['baseline_begEnd_samp'], save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### calculate all the color limits for heatmaps; useful for locking color limits across different heatmap subplots\n",
    "\n",
    "# for trial_avg data, get min/max across conditions\n",
    "clims_data = [ np.nanmin( [np.mean(data_dict[key]['data'], axis = 0) for key in data_dict] ), \n",
    "        np.nanmax( [np.mean(data_dict[key]['data'], axis = 0) for key in data_dict] ) ]\n",
    "\n",
    "## for z-scored data, we'd like for the color scale to be centered at 0; first we get color limits\n",
    "tmp_clim = [ np.nanmin( [data_dict[key]['ztrial_avg_data'] for key in data_dict] ), \n",
    "        np.nanmax( [data_dict[key]['ztrial_avg_data'] for key in data_dict] ) ]\n",
    "# then we take the higher of the two magnitudes\n",
    "clims_max = np.max(np.abs(tmp_clim))\n",
    "# and set it as the negative and positive limit for plotting\n",
    "clims_z = [-clims_max*0.5, clims_max*0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_init(data_dict):\n",
    "    color_limits = {}\n",
    "\n",
    "    color_limits['clims_data'] = [ np.nanmin( [np.mean(data_dict[key]['data'], axis = 0) for key in data_dict] ), \n",
    "            np.nanmax( [np.mean(data_dict[key]['data'], axis = 0) for key in data_dict] ) ]\n",
    "\n",
    "    tmp_clim = [ np.nanmin( [data_dict[key]['ztrial_avg_data'] for key in data_dict] ), \n",
    "            np.nanmax( [data_dict[key]['ztrial_avg_data'] for key in data_dict] ) ]\n",
    "\n",
    "    clims_max = np.max(np.abs(tmp_clim))\n",
    "\n",
    "    color_limits['clims_z'] = [-clims_max*0.5, clims_max*0.5]    \n",
    "\n",
    "    return color_limits   \n",
    "\n",
    "color_limits = color_init(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trial-resolved heatmap for each ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_trial_heatmap(data_in, conditions, tvec, event_bound_ratio, clims, n_rows, n_columns, \n",
    "                           save_fig = False, axis_label_size=15):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prep information about specific condition (each loop) and plot heatmap\n",
    "        1) x/y label tick values\n",
    "        2) x/y labels\n",
    "        3) grab specific condition's data\n",
    "        4) plot data (using utils function)\n",
    "        5) plot meta data lines (eg. 0-time line, event duration line)\n",
    "\n",
    "    event_bound_ratio\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx_cond, cond in enumerate(conditions):\n",
    "        \n",
    "        # set imshow extent to replace x and y axis ticks/labels\n",
    "        plot_extent = [tvec[0], tvec[-1], data_in[cond]['num_trials'], 0] # [x min, x max, y min, ymax]\n",
    "        \n",
    "        # determine subplot location index\n",
    "        subplot_index = subplot_loc(idx_cond, n_rows, n_columns)\n",
    "        \n",
    "        # prep labels; plot x and y labels for first subplot\n",
    "        if subplot_index == (0, 0) or subplot_index == 0 :\n",
    "            ax[subplot_index].set_ylabel('Trial', fontsize=axis_label_size)\n",
    "            ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "        ax[subplot_index].tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "        \n",
    "        # prep the data\n",
    "        to_plot = np.squeeze(data_in[cond]['data'][...,iROI,:]) \n",
    "        if len(event_frames[cond]) == 1: # accomodates single trial data\n",
    "            to_plot = to_plot[np.newaxis, :]\n",
    "        \n",
    "        # plot the data\n",
    "        title = 'ROI {}; {}'.format(str(iROI), cond)\n",
    "        im = utils.subplot_heatmap(ax[subplot_index], title, to_plot, cmap='inferno', clims=clims, extent_=plot_extent)\n",
    "        \n",
    "        # add meta data lines\n",
    "        ax[subplot_index].axvline(0, color='0.5', alpha=1) # plot vertical line for time zero\n",
    "        # plots green horizontal line indicating event duration\n",
    "        ax[subplot_index].annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                                   xytext=(event_bound_ratio[1], -0.01), \n",
    "                                   arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "\n",
    "    cbar = fig.colorbar(im, ax = ax[subplot_index], shrink = 0.5)\n",
    "    cbar.ax.set_ylabel('Activity', fontsize = axis_label_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_subplots = len(conditions) + 1 # plus one for trial-avg traces\n",
    "n_columns = np.min([num_subplots, 4.0])\n",
    "n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "for iROI in range(num_rois):\n",
    "     \n",
    "    ## Plot heatmaps for each condition\n",
    "    roi_clims = [ np.nanmin( [np.nanmin(data_dict[cond]['data'][...,iROI,:]) for cond in conditions] ), \n",
    "        np.nanmax( [np.nanmax(data_dict[cond]['data'][...,iROI,:]) for cond in conditions] ) ]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), \n",
    "                           figsize=(n_columns*4, n_rows*3),\n",
    "                           constrained_layout=True)\n",
    "    \n",
    "    subplot_trial_heatmap(data_dict, conditions, tvec, event_bound_ratio, roi_clims, n_rows, n_columns, \n",
    "                           save_fig=False)\n",
    "    \n",
    "    ## plot last subplot of trial-avg traces\n",
    "    \n",
    "    # determine subplot location index\n",
    "    subplot_index = subplot_loc(num_subplots-1, n_rows, n_columns)\n",
    "\n",
    "    for cond in conditions:\n",
    "        \n",
    "        # prep data to plot\n",
    "        num_trials = data_dict[cond]['num_trials']\n",
    "        to_plot = np.nanmean(data_dict[cond]['zdata'][:,iROI,:], axis=0)\n",
    "        to_plot_err = np.nanstd(data_dict[cond]['zdata'][:,iROI,:], axis=0)/np.sqrt(num_trials)\n",
    "        \n",
    "        # plot trace\n",
    "        ax[subplot_index].plot(tvec, to_plot)\n",
    "        if fparams['opto_blank_frame']: \n",
    "            ax[subplot_index].plot(tvec[t0_sample:event_end_sample], to_plot[t0_sample:event_end_sample], marker='.', color='g')\n",
    "        # plot shaded error\n",
    "        if fparams['flag_trial_avg_errbar']:\n",
    "            ax[subplot_index].fill_between(tvec, to_plot - to_plot_err, to_plot + to_plot_err,\n",
    "                         alpha=0.5) # this plots the shaded error bar\n",
    "        \n",
    "    # plot x, y labels, and legend\n",
    "    ax[subplot_index].set_ylabel('Z-Score Activity', fontsize=axis_label_size)\n",
    "    ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size)\n",
    "    ax[subplot_index].set_title('ROI # {}; Trial-avg'.format(str(iROI)), fontsize=axis_label_size)\n",
    "    ax[subplot_index].legend(conditions)\n",
    "    ax[subplot_index].autoscale(enable=True, axis='both', tight=True)\n",
    "    ax[subplot_index].axvline(0, color='0.5', alpha=0.65) # plot vertical line for time zero\n",
    "    ax[subplot_index].annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                                   xytext=(event_bound_ratio[1], -0.01), \n",
    "                                   arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "    ax[subplot_index].tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "    \n",
    "    for a in ax.flat[num_subplots:]:\n",
    "        a.axis('off')\n",
    "    \n",
    "    if fparams['flag_save_figs']:\n",
    "        fig.savefig( os.path.join(save_dir,'roi_{}_activity.png'.format(str(iROI))) ); \n",
    "        fig.savefig( os.path.join(save_dir,'roi_{}_activity.pdf'.format(str(iROI))) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_heatmap_plot(data_dict, fparams, event_data, roi_info, behav_data):\n",
    "    num_subplots = len(behav_data['conditions']) + 1 # plus one for trial-avg traces\n",
    "    n_columns = np.min([num_subplots, 4.0])\n",
    "    n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "    for iROI in range(roi_info['num_rois']):\n",
    "        \n",
    "        ## Plot heatmaps for each condition\n",
    "        roi_clims = [ np.nanmin( [np.nanmin(data_dict[cond]['data'][...,iROI,:]) for cond in behav_data['conditions']] ), \n",
    "            np.nanmax( [np.nanmax(data_dict[cond]['data'][...,iROI,:]) for cond in behav_data['conditions']] ) ]\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), \n",
    "                            figsize=(n_columns*4, n_rows*3),\n",
    "                            constrained_layout=True)\n",
    "        \n",
    "        subplot_trial_heatmap(data_dict, behav_data['conditions'], event_data['tvec'], event_data['event_bound_ratio'], roi_clims, n_rows, n_columns, \n",
    "                            save_fig=False)\n",
    "        \n",
    "        ## plot last subplot of trial-avg traces\n",
    "        \n",
    "        # determine subplot location index\n",
    "        subplot_index = subplot_loc(num_subplots-1, n_rows, n_columns)\n",
    "\n",
    "        for cond in behav_data['conditions']:\n",
    "            \n",
    "            # prep data to plot\n",
    "            num_trials = data_dict[cond]['num_trials']\n",
    "            to_plot = np.nanmean(data_dict[cond]['zdata'][:,iROI,:], axis=0)\n",
    "            to_plot_err = np.nanstd(data_dict[cond]['zdata'][:,iROI,:], axis=0)/np.sqrt(num_trials)\n",
    "            \n",
    "            # plot trace\n",
    "            ax[subplot_index].plot(event_data['tvec'], to_plot)\n",
    "            if fparams['opto_blank_frame']: \n",
    "                ax[subplot_index].plot(event_data['tvec'][event_data['t0_sample']:event_data['event_end_sample']], to_plot[event_data['t0_sample']:event_data['event_end_sample']], marker='.', color='g')\n",
    "            # plot shaded error\n",
    "            if fparams['flag_trial_avg_errbar']:\n",
    "                ax[subplot_index].fill_between(event_data['tvec'], to_plot - to_plot_err, to_plot + to_plot_err,\n",
    "                            alpha=0.5) # this plots the shaded error bar\n",
    "            \n",
    "        # plot x, y labels, and legend\n",
    "        ax[subplot_index].set_ylabel('Z-Score Activity', fontsize=axis_label_size)\n",
    "        ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size)\n",
    "        ax[subplot_index].set_title('ROI # {}; Trial-avg'.format(str(iROI)), fontsize=axis_label_size)\n",
    "        ax[subplot_index].legend(event_data['conditions'])\n",
    "        ax[subplot_index].autoscale(enable=True, axis='both', tight=True)\n",
    "        ax[subplot_index].axvline(0, color='0.5', alpha=0.65) # plot vertical line for time zero\n",
    "        ax[subplot_index].annotate('', xy=(event_data['event_bound_ratio'][0], -0.01), xycoords='axes fraction', \n",
    "                                    xytext=(event_data['event_bound_ratio'][1], -0.01), \n",
    "                                    arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "        ax[subplot_index].tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "        \n",
    "        for a in ax.flat[num_subplots:]:\n",
    "            a.axis('off')\n",
    "        \n",
    "        if fparams['flag_save_figs']:\n",
    "            fig.savefig( os.path.join(fparams['save_dir'],'roi_{}_activity.png'.format(str(iROI))) ); \n",
    "            fig.savefig( os.path.join(fparams['save_dir'],'roi_{}_activity.pdf'.format(str(iROI))) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonymous function to find closest sample when a time occurs in a time vector\n",
    "tvec = event_data['tvec']\n",
    "tvec2samp = lambda tvec, time: np.argmin(np.abs(tvec - time))\n",
    "\n",
    "# function to sort ROIs based on activity in certain epoch\n",
    "def sort_heatmap_peaks(data, tvec, sort_epoch_start_time, sort_epoch_end_time, sort_method = 'peak_time'):\n",
    "    \n",
    "    # find start/end samples for epoch\n",
    "    sort_epoch_start_samp = tvec2samp(tvec, sort_epoch_start_time)\n",
    "    sort_epoch_end_samp = tvec2samp(tvec, sort_epoch_end_time)\n",
    "    \n",
    "    if sort_method == 'peak_time':\n",
    "        epoch_peak_samp = np.argmax(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.argsort(epoch_peak_samp)\n",
    "    elif sort_method == 'max_value':\n",
    " \n",
    "        time_max = np.nanmax(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.argsort(time_max)[::-1]\n",
    "\n",
    "    return final_sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if flag is true, sort ROIs (usually by average fluorescence within analysis window)\n",
    "if fparams['flag_sort_rois']:\n",
    "    if not fparams['roi_sort_cond']: # if no condition to sort by specified, use first condition\n",
    "        fparams['roi_sort_cond'] = data_dict.keys()[0]\n",
    "    if not fparams['roi_sort_cond'] in data_dict.keys():\n",
    "        sorted_roi_order = range(num_rois)\n",
    "        interesting_rois = fparams['interesting_rois']\n",
    "        print('Specified condition to sort by doesn\\'t exist! ROIs are in default sorting.')\n",
    "    else:\n",
    "        # returns new order of rois sorted using the data and method supplied in the specified window\n",
    "        sorted_roi_order = sort_heatmap_peaks(data_dict[fparams['roi_sort_cond']]['ztrial_avg_data'], tvec, \n",
    "                           sort_epoch_start_time=0, \n",
    "                           sort_epoch_end_time = trial_start_end_sec[-1], \n",
    "                           sort_method = fparams['user_sort_method'])\n",
    "        # finds corresponding interesting roi (roi's to mark with an arrow) order after sorting\n",
    "        interesting_rois = np.in1d(sorted_roi_order, fparams['interesting_rois']).nonzero()[0] \n",
    "else:\n",
    "    sorted_roi_order = range(num_rois)\n",
    "    interesting_rois = fparams['interesting_rois']\n",
    "\n",
    "if not all_nan_rois[0].size == 0:\n",
    "    set_diff_keep_order = lambda main_list, remove_list : [i for i in main_list if i not in remove_list]\n",
    "    sorted_roi_order = set_diff_keep_order(sorted_roi_order, all_nan_rois)\n",
    "    interesting_rois = [i for i in fparams['interesting_rois'] if i not in all_nan_rois]\n",
    "    \n",
    "roi_order_path = os.path.join(fparams['fdir'], fparams['fname'] + '_roi_order.pkl')\n",
    "with open(roi_order_path, 'wb') as handle:\n",
    "     pickle.dump(sorted_roi_order, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_rois(data_dict, fparams, event_data, roi_info):\n",
    "    # if flag is true, sort ROIs (usually by average fluorescence within analysis window)\n",
    "    if fparams['flag_sort_rois']:\n",
    "        if not fparams['roi_sort_cond']: # if no condition to sort by specified, use first condition\n",
    "            fparams['roi_sort_cond'] = data_dict.keys()[0]\n",
    "        if not fparams['roi_sort_cond'] in data_dict.keys():\n",
    "            sorted_roi_order = range(roi_info['num_rois'])\n",
    "            interesting_rois = fparams['interesting_rois']\n",
    "            print('Specified condition to sort by doesn\\'t exist! ROIs are in default sorting.')\n",
    "        else:\n",
    "            # returns new order of rois sorted using the data and method supplied in the specified window\n",
    "            sorted_roi_order = sort_heatmap_peaks(data_dict[fparams['roi_sort_cond']]['ztrial_avg_data'], event_data['tvec'], \n",
    "                            sort_epoch_start_time=0, \n",
    "                            sort_epoch_end_time = trial_start_end_sec[-1], \n",
    "                            sort_method = fparams['user_sort_method'])\n",
    "            # finds corresponding interesting roi (roi's to mark with an arrow) order after sorting\n",
    "            interesting_rois = np.in1d(sorted_roi_order, fparams['interesting_rois']).nonzero()[0] \n",
    "    else:\n",
    "        sorted_roi_order = range(num_rois)\n",
    "        interesting_rois = fparams['interesting_rois']\n",
    "\n",
    "    if not all_nan_rois[0].size == 0:\n",
    "        set_diff_keep_order = lambda main_list, remove_list : [i for i in main_list if i not in remove_list]\n",
    "        sorted_roi_order = set_diff_keep_order(sorted_roi_order, all_nan_rois)\n",
    "        interesting_rois = [i for i in fparams['interesting_rois'] if i not in all_nan_rois]\n",
    "        \n",
    "    roi_order_path = os.path.join(fparams['fdir'], fparams['fname'] + '_roi_order.pkl')\n",
    "    with open(roi_order_path, 'wb') as handle:\n",
    "        pickle.dump(sorted_roi_order, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return interesting_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_trial_avg_heatmap(data_in, conditions, tvec, event_bound_ratio, clims, sorted_roi_order = None, \n",
    "                           rois_oi = None, save_fig = False, axis_label_size=15):\n",
    "    \n",
    "    \"\"\"\n",
    "    Technically doesn't need to remove all_nan_rois b/c of nanmean calculations\n",
    "    \"\"\"\n",
    "    \n",
    "    num_subplots = len(conditions)\n",
    "    n_columns = np.min([num_subplots, 3.0])\n",
    "    n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "    # set imshow extent to replace x and y axis ticks/labels (replace samples with time)\n",
    "    plot_extent = [tvec[0], tvec[-1], num_rois, 0 ]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), figsize = (n_columns*5, n_rows*4))\n",
    "    if not isinstance(ax,np.ndarray): # this is here to make the code below compatible with indexing a single subplot object\n",
    "        ax = [ax]\n",
    "\n",
    "    for idx, cond in enumerate(conditions):\n",
    "\n",
    "        # determine subplot location index\n",
    "        if n_rows == 1:\n",
    "            subplot_index = idx\n",
    "        else:\n",
    "            subplot_index = np.unravel_index(idx, (n_rows, int(n_columns))) # turn int index to a tuple of array coordinates\n",
    "\n",
    "        # prep labels; plot x and y labels for first subplot\n",
    "        if subplot_index == (0, 0) or subplot_index == 0 :\n",
    "            ax[subplot_index].set_ylabel('ROI #', fontsize=axis_label_size)\n",
    "            ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "        ax[subplot_index].tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "        \n",
    "        # plot the data\n",
    "        if sorted_roi_order is not None:\n",
    "            roi_order = sorted_roi_order\n",
    "        else:\n",
    "            roi_order = slice(0, num_rois)\n",
    "        to_plot = data_in[cond]['ztrial_avg_data'][roi_order,:] # \n",
    "\n",
    "        im = utils.subplot_heatmap(ax[subplot_index], cond, to_plot, clims = clims, extent_=plot_extent)\n",
    "        ax[subplot_index].axvline(0, color='k', alpha=0.3) # plot vertical line for time zero\n",
    "        ax[subplot_index].annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                                       xytext=(event_bound_ratio[1], -0.01), \n",
    "                                       arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "        if rois_oi is not None:\n",
    "            for ROI_OI in rois_oi:\n",
    "                ax[subplot_index].annotate('', xy=(1.005, 1-(ROI_OI/num_rois)-0.015), xycoords='axes fraction', \n",
    "                                           xytext=(1.06, 1-(ROI_OI/num_rois)-0.015), \n",
    "                                           arrowprops=dict(arrowstyle=\"->\", color='k'))\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    cbar = fig.colorbar(im, ax = ax, shrink = 0.7)\n",
    "    cbar.ax.set_ylabel('Z-Score Activity', fontsize=13)\n",
    "    \n",
    "    # hide empty subplot\n",
    "    for a in ax.flat[num_subplots:]:\n",
    "        a.axis('off')\n",
    "    \n",
    "    if save_fig:\n",
    "        fig.savefig(os.path.join(save_dir,'trial_avg_heatmap.png')); \n",
    "        fig.savefig(os.path.join(save_dir,'trial_avg_heatmap.pdf'));\n",
    "\n",
    "plot_trial_avg_heatmap(data_dict, behav_data['conditions'], event_data['tvec'], event_data['event_bound_ratio'], clims = clims_z,\n",
    "                       sorted_roi_order = sorted_roi_order, rois_oi = interesting_rois, save_fig = fparams['flag_save_figs'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trial- and ROI-averaged traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line_shades = []\n",
    "fig, axs = plt.subplots(1,1, figsize = (10,6))\n",
    "for idx, cond in enumerate(conditions):\n",
    "    line_color = cmap_lines(idx)\n",
    "    # first trial avg the data\n",
    "    trial_avg = np.nanmean(data_dict[cond]['zdata'], axis=0)\n",
    "    \n",
    "    # z-score trial-avg data for each respective ROI\n",
    "    # apply zscore function to each row of data\n",
    "    app_axis = 1 \n",
    "    zscore_trial_avg = np.apply_along_axis(utils.zscore_, app_axis, trial_avg, baseline_svec)\n",
    "    \n",
    "    # take avg/std across ROIs\n",
    "    zscore_roi_trial_avg = np.nanmean(zscore_trial_avg, axis=0)\n",
    "    zscore_roi_trial_std = np.nanstd(zscore_trial_avg, axis=0)\n",
    "     \n",
    "    to_plot = np.squeeze(zscore_roi_trial_avg)\n",
    "    to_plot_err = np.squeeze(zscore_roi_trial_std)/np.sqrt(num_rois)\n",
    "    \n",
    "    axs.plot(tvec, to_plot, color=line_color)\n",
    "    if fparams['opto_blank_frame']:\n",
    "        line = axs.plot(tvec[t0_sample:event_end_sample], to_plot[t0_sample:event_end_sample], marker='.', color=line_color)\n",
    "    else:\n",
    "        line = axs.plot(tvec[t0_sample:event_end_sample], to_plot[t0_sample:event_end_sample], color=line_color)\n",
    "    \n",
    "    if fparams['flag_roi_trial_avg_errbar']:\n",
    "        shade = axs.fill_between(tvec, to_plot - to_plot_err, to_plot + to_plot_err, color = line_color,\n",
    "                     alpha=0.2) # this plots the shaded error bar\n",
    "        line_shades.append((line[0],shade))\n",
    "            \n",
    "axs.set_ylabel('Z-score Activity', fontsize=axis_label_size)\n",
    "axs.set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "axs.legend(conditions);\n",
    "axs.legend(line_shades, conditions, fontsize=15)\n",
    "axs.axvline(0, color='0.5', alpha=0.65) # plot vertical line for time zero\n",
    "axs.annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                               xytext=(event_bound_ratio[1], -0.01), \n",
    "                               arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "axs.tick_params(axis = 'both', which = 'major', labelsize = tick_font_size+3)\n",
    "axs.autoscale(enable=True, axis='both', tight=True)\n",
    "\n",
    "#axs.set_ylim([-1.5, 10])\n",
    "\n",
    "if fparams['flag_save_figs']:\n",
    "        fig.savefig(os.path.join(save_dir,'roi_trial_avg_trace.png')); fig.savefig(os.path.join(save_dir,'roi_trial_avg_trace.pdf'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmaps_across_rois_plot(fparams, event_data, roi_info, behav_data): \n",
    "    line_shades = []\n",
    "    fig, axs = plt.subplots(1,1, figsize = (10,6))\n",
    "    for idx, cond in enumerate(behav_data['conditions']):\n",
    "        line_color = cmap_lines(idx)\n",
    "        # first trial avg the data\n",
    "        trial_avg = np.nanmean(data_dict[cond]['zdata'], axis=0)\n",
    "        \n",
    "        # z-score trial-avg data for each respective ROI\n",
    "        # apply zscore function to each row of data\n",
    "        app_axis = 1 \n",
    "        zscore_trial_avg = np.apply_along_axis(utils.zscore_, app_axis, trial_avg, event_data['baseline_svec'])\n",
    "        \n",
    "        # take avg/std across ROIs\n",
    "        zscore_roi_trial_avg = np.nanmean(zscore_trial_avg, axis=0)\n",
    "        zscore_roi_trial_std = np.nanstd(zscore_trial_avg, axis=0)\n",
    "        \n",
    "        to_plot = np.squeeze(zscore_roi_trial_avg)\n",
    "        to_plot_err = np.squeeze(zscore_roi_trial_std)/np.sqrt(roi_info['num_rois'])\n",
    "        \n",
    "        axs.plot(event_data['tvec'], to_plot, color=line_color)\n",
    "        if fparams['opto_blank_frame']:\n",
    "            line = axs.plot(event_data['tvec'][event_data['t0_sample']:event_data['event_end_sample']], to_plot[event_data['t0_sample']:event_data['event_end_sample']], marker='.', color=line_color)\n",
    "        else:\n",
    "            line = axs.plot(event_data['tvec'][event_data['t0_sample']:event_data['event_end_sample']], to_plot[event_data['t0_sample']:event_data['event_end_sample']], color=line_color)\n",
    "        \n",
    "        if fparams['flag_roi_trial_avg_errbar']:\n",
    "            shade = axs.fill_between(event_data['tvec'], to_plot - to_plot_err, to_plot + to_plot_err, color = line_color,\n",
    "                        alpha=0.2) # this plots the shaded error bar\n",
    "            line_shades.append((line[0],shade))\n",
    "                \n",
    "    axs.set_ylabel('Z-score Activity', fontsize=axis_label_size)\n",
    "    axs.set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "    axs.legend(behav_data['conditions']);\n",
    "    axs.legend(line_shades, behav_data['conditions'], fontsize=15)\n",
    "    axs.axvline(0, color='0.5', alpha=0.65) # plot vertical line for time zero\n",
    "    axs.annotate('', xy=(event_data['event_bound_ratio'][0], -0.01), xycoords='axes fraction', \n",
    "                                xytext=(event_data['event_bound_ratio'][1], -0.01), \n",
    "                                arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "    axs.tick_params(axis = 'both', which = 'major', labelsize = tick_font_size+3)\n",
    "    axs.autoscale(enable=True, axis='both', tight=True)\n",
    "\n",
    "    #axs.set_ylim([-1.5, 10])\n",
    "\n",
    "    if fparams['flag_save_figs']:\n",
    "            fig.savefig(os.path.join(fparams['save_dir'],'roi_trial_avg_trace.png')); fig.savefig(os.path.join(fparams['save_dir'],'roi_trial_avg_trace.pdf'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for finding the index of the closest entry in an array to a provided value\n",
    "def find_nearest_idx(array, value):\n",
    "\n",
    "    if isinstance(array, pd.Series):\n",
    "        idx = (np.abs(array - value)).idxmin()\n",
    "        return idx, array.index.get_loc(idx), array[idx] # series index, 0-relative index, entry value\n",
    "    else:\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return idx, array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Quantification of roi-, trial-, time-averaged data\n",
    "\n",
    "analysis_window = fparams['event_sort_analysis_win']\n",
    "analysis_win_samps = [ find_nearest_idx(tvec, time)[0] for time in analysis_window ]\n",
    "\n",
    "to_plot = []\n",
    "to_plot_err = []\n",
    "\n",
    "fig, axs = plt.subplots(1,1, figsize = (5,5))\n",
    "for idx, cond in enumerate(conditions):\n",
    "    line_color = cmap_lines(idx)\n",
    "    # first trial avg the data\n",
    "    trial_avg = np.nanmean(data_dict[cond]['zdata'], axis=0)\n",
    "    \n",
    "    # z-score trial-avg data for each respective ROI\n",
    "    # apply zscore function to each row of data\n",
    "    apply_axis = 1 \n",
    "    zscore_trial_avg = np.apply_along_axis(utils.zscore_, apply_axis, trial_avg, baseline_svec)\n",
    "    \n",
    "    # take avg across time\n",
    "    zscore_trial_time_avg = np.nanmean(zscore_trial_avg[:,analysis_win_samps[0]:analysis_win_samps[1],:], axis=1)\n",
    "    \n",
    "    # take avg/std across ROIs\n",
    "    zscore_roi_trial_time_avg = np.nanmean(zscore_trial_time_avg, axis=0)\n",
    "    zscore_roi_trial_time_std = np.nanstd(zscore_trial_time_avg, axis=0)\n",
    "     \n",
    "    to_plot.append(zscore_roi_trial_time_avg[0])\n",
    "    to_plot_err.append(zscore_roi_trial_time_std[0]/np.sqrt(len(zscore_trial_time_avg)))\n",
    "    \n",
    "barlist = axs.bar(conditions, to_plot, yerr=to_plot_err, align='center', alpha=0.5, ecolor='black', capsize=10 )\n",
    "for idx in range(len(conditions)):\n",
    "    barlist[idx].set_color(cmap_lines(idx))\n",
    "axs.set_ylabel('Normalized Fluorescence', fontsize=13)\n",
    "axs.set_title('ROI-, Trial-, Time-averaged Quant', fontsize=15)\n",
    "axs.yaxis.grid(True)\n",
    "axs.tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "axs.tick_params(axis = 'x', which = 'major', rotation = 45)\n",
    "# Save the figure and show\n",
    "plt.tight_layout()\n",
    "\n",
    "if fparams['flag_save_figs']:\n",
    "    fig.savefig(os.path.join(save_dir,'roi_trial_time_avg_bar.png')); \n",
    "    fig.savefig(os.path.join(save_dir,'roi_trial_time_avg_bar.pdf'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_averaged_quantification_plot(data_dict, fparams, event_data, behav_data):\n",
    "    analysis_window = fparams['event_sort_analysis_win']\n",
    "    analysis_win_samps = [ find_nearest_idx(event_data['tvec'], time)[0] for time in analysis_window ]\n",
    "\n",
    "    to_plot = []\n",
    "    to_plot_err = []\n",
    "\n",
    "    fig, axs = plt.subplots(1,1, figsize = (5,5))\n",
    "    for idx, cond in enumerate(behav_data['conditions']):\n",
    "        line_color = cmap_lines(idx)\n",
    "        # first trial avg the data\n",
    "        trial_avg = np.nanmean(data_dict[cond]['zdata'], axis=0)\n",
    "        \n",
    "        # z-score trial-avg data for each respective ROI\n",
    "        # apply zscore function to each row of data\n",
    "        apply_axis = 1 \n",
    "        zscore_trial_avg = np.apply_along_axis(utils.zscore_, apply_axis, trial_avg, event_data['baseline_svec'])\n",
    "        \n",
    "        # take avg across time\n",
    "        zscore_trial_time_avg = np.nanmean(zscore_trial_avg[:,analysis_win_samps[0]:analysis_win_samps[1],:], axis=1)\n",
    "        \n",
    "        # take avg/std across ROIs\n",
    "        zscore_roi_trial_time_avg = np.nanmean(zscore_trial_time_avg, axis=0)\n",
    "        zscore_roi_trial_time_std = np.nanstd(zscore_trial_time_avg, axis=0)\n",
    "        \n",
    "        to_plot.append(zscore_roi_trial_time_avg[0])\n",
    "        to_plot_err.append(zscore_roi_trial_time_std[0]/np.sqrt(len(zscore_trial_time_avg)))\n",
    "        \n",
    "    barlist = axs.bar(behav_data['conditions'], to_plot, yerr=to_plot_err, align='center', alpha=0.5, ecolor='black', capsize=10 )\n",
    "    for idx in range(len(behav_data['conditions'])):\n",
    "        barlist[idx].set_color(cmap_lines(idx))\n",
    "    axs.set_ylabel('Normalized Fluorescence', fontsize=13)\n",
    "    axs.set_title('ROI-, Trial-, Time-averaged Quant', fontsize=15)\n",
    "    axs.yaxis.grid(True)\n",
    "    axs.tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "    axs.tick_params(axis = 'x', which = 'major', rotation = 45)\n",
    "    # Save the figure and show\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if fparams['flag_save_figs']:\n",
    "        fig.savefig(os.path.join(fparams['save_dir'],'roi_trial_time_avg_bar.png')); \n",
    "        fig.savefig(os.path.join(fparams['save_dir'],'roi_trial_time_avg_bar.pdf'));"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29f2007cb673592858fd6523f43b39cf3f3163925deee452a0b41f2064912f2a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('napeca_post')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
