{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPE Calcium Imaging Event-Related Analysis\n",
    "\n",
    "## What does this script do:\n",
    "\n",
    "Loads activity traces from ROIs/sources across the whole session as well as timing of behavioral/manipulation events, then extracts a window of activity around each event, and finally generates numerous event-related plots resolving and averaging across trials and ROIs.\n",
    "\n",
    "How to run this code\n",
    "------------------------------------\n",
    "\n",
    "In this jupyter notebook, First find the code block with the comment header called USER-DEFINED VARIABLES. Edit the variables according to your data and output preferences. Then just run all cells in order (shift + enter; or in the dropdown menu: Kernel->Resart & Run All). Please make sure you set the correct sampling rate (fs) in the user-defined variables block of code.\n",
    "\n",
    "### Required Prerequisite/Input Files\n",
    "\n",
    "All data should reside in a parent folder. This folder's name should be the name of the session and ideally be the same as the base name of the recording file.\n",
    "\n",
    "1. ROI/source activity signals file ( `fparams['fname_signal']` ): This is either a npy or CSV file where rows are individual ROIs/sources and columns are samples, and the values are activity levels (ie. fluorescence or voltage for ephys). Note the CSV should not \n",
    "2. Event occurrence file (`fparams['fname_events']` ): This is either a pickle file or a CSV file. For the pickle file, it should contain a python dictionary where keys are event condition names and associated values are lists that contain event occurrence times (in samples). If using a CSV, the data should be in tidy format formated like what is shown here (note currently the first row, first and second columns should be \"event\" and \"sample\" respectively: https://github.com/zhounapeuw/NAPE_imaging_postprocess/raw/main/docs/_images/napeca_post_event_csv_format.png\n",
    "\n",
    "\n",
    "Required Packages\n",
    "-----------------\n",
    "Python 3.7, seaborn, matplotlib, pandas, scikit-learn\n",
    "\n",
    "Custom code requirements: utils\n",
    "\n",
    "User-Defined Parameters \n",
    "----------\n",
    "\n",
    "fname_signal : string\n",
    "    \n",
    "    Name of file that contains roi activity traces. Must include full file name with extension. Accepted file types: .npy, .csv. IMPORTANT: data dimensions should be rois (y) by samples/time (x)\n",
    "\n",
    "fname_events : string\n",
    "\n",
    "    Name of file that contains event occurrences. Must include full file name with extension. Accepted file types: .pkl, .csv. Pickle (pkl) files need to contain a dictionary where keys are the condition names and the values are lists containing samples/frames for each corresponding event. Csv's should have two columns (event condition, sample). The first row are the column names. Subsequent rows contain each trial's event condition and sample in tidy format. See example in sample_data folder for formatting, or this link: https://github.com/zhounapeuw/NAPE_imaging_postprocess/raw/main/docs/_images/napeca_post_event_csv_format.png\n",
    "\n",
    "fdir : string \n",
    "\n",
    "    Root file directory containing the raw tif, tiff, h5 files. IMPORTANT Note: leave off the last backslash, and include the letter r in front of string (treats the contents as a raw string). For example: r'C:\\Users\\my_user\\analyze_sessions'\n",
    "\n",
    "fname : string\n",
    "\n",
    "    Session name; by default this is the name of the parent folder that the data resides in, but can be changed by user to be any string. This fname variable is mainly used to name the saved output files.\n",
    "\n",
    "flag_save_figs : boolean  \n",
    "\n",
    "    Set as True to save figures as JPG and vectorized formats.  \n",
    "    \n",
    "fs : float\n",
    "\n",
    "    Sampling rate of imaging data. It is imperative that this value is correct; otherwise the incorrect time windows will be pulled out for each event. If you suspect that \n",
    "    the sampling rate (fs) was not set correctly in the NAPECA preprocessing pipeline, go into the saved json file and edit the fs value.\n",
    "    \n",
    "selected_conditions : list of strings\n",
    "\n",
    "    Specific conditions that the user wants to analyze; needs to be exactly the name of conditions in the events CSV or pickle file\n",
    "\n",
    "trial_start_end : list of two entries  \n",
    "\n",
    "    Entries can be ints or floats. The first entry is the time in seconds relative to the event/ttl onset for the start of the event analysis window (negative if before the event/ttl onset. The second entry is the time in seconds for the end of the event analysis window. For example if the desired analysis window is 5.5 seconds before event onset and 8 seconds after, `trial_start_end` would be [-5.5, 8].  \n",
    "    \n",
    "baseline_end : int/float  \n",
    "\n",
    "    Time in seconds for the end of the baseline epoch. By default, the baseline epoch start time will be the first entry ot `trial_start_end`. This baseline epoch is used for calculating baseline normalization metrics.\n",
    "    \n",
    "event_dur : int/float  \n",
    "\n",
    "    Time in seconds representing how long the behavioral event or stimulation, etc. lasts. A green line with the corresponding length will be plotted indicating stimulus duration\n",
    "\n",
    "event_sort_analysis_win : list with two float entries\n",
    "\n",
    "    Time window [a, b] in seconds during which some visualization calculations will apply to. For example, if the user sets flag_sort_rois to be True, ROIs in heatmaps will be sorted based on the mean activity in the time window between a and b. Similar principle holds for the time-averaged barplots.\n",
    "\n",
    "opto_blank_frame : boolean\n",
    "\n",
    "    if PMTs were blanked during stim, use detected stim times (from preprocessing) to set those frames to NaN\n",
    "\n",
    "flag_npil_corr : boolean  \n",
    "\n",
    "    Set as True if user would like to load in neuropil corrected data from the preprocessing pipeline. Must have a \\*\\_neuropil\\_corrected_signal_* file in the directory. If set as False, just use the extracted_signal file.\n",
    "    \n",
    "flag_zscore : boolean  \n",
    "\n",
    "    Set as True if analyzed data should be baseline z-scored on a trial level.  \n",
    "\n",
    "flag_sort_rois : boolean\n",
    "\n",
    "    Set as True to sort ROIs on the y axis of heatmaps. This works with `user_sort_method` and `roi_sort_cond` for specifying details of sorting.\n",
    "\n",
    "user_sort_method : string\n",
    "    \n",
    "    Set to 'peak_time' to sort ROIs by peak time during event_sort_dur; 'max_value' to sort by max value\n",
    "    \n",
    "roi_sort_cond : string\n",
    "    \n",
    "    Condition to perform sorting on\n",
    "\n",
    "flag_roi_trial_avg_errbar : boolean  \n",
    "\n",
    "    Set as True to set standard error of mean shaded portions for line plots of trial-averaged activity.   \n",
    "\n",
    "flag_trial_avg_errbar : boolean\n",
    "\n",
    "    toggle standard error bars on trial-averaged data\n",
    "\n",
    "interesting_rois : list of ints  \n",
    "\n",
    "    All entries are indices for ROIs that will be marked in heatmaps by arrows.  \n",
    "\n",
    "Optional Parameters (Only relevant if using batch_process)\n",
    "-------------------\n",
    "\n",
    "user_sort_method : string\n",
    "    \n",
    "    Takes the strings 'peak_time' or 'max_value'\n",
    "    \n",
    "    \n",
    "roi_sort_cond : string\n",
    "    for roi-resolved heatmaps, which condition to sort ROIs by\n",
    "    \n",
    "    Defaults to first condition available\n",
    "    \n",
    "Output\n",
    "-------\n",
    "\n",
    "event_rel_analysis : folder containing plots in jpg/png and vectorized formats\n",
    "\n",
    "event_data_dict.pkl : pickle file containing a dictionary containing event-triggered data from each cell and organized by event condition. Raw and z-scored data are included as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#important for text to be detected when importing saved figures into illustrator\n",
    "matplotlib.rcParams['pdf.fonttype']=42\n",
    "matplotlib.rcParams['ps.fonttype']=42\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple class to update limits as you go through iterations of data\n",
    "# first call update_lims(first_lims)\n",
    "# then update_lims.update(new_lims)\n",
    "# update_lims.output() outputs lims\n",
    "class update_lims:\n",
    "    \n",
    "    def __init__(self, lims):\n",
    "        self.lims = lims\n",
    "        \n",
    "    \n",
    "    def update(self, new_lims):\n",
    "        if self.lims[0] > new_lims[0]:\n",
    "            self.lims[0] = new_lims[0]\n",
    "        \n",
    "        if self.lims[1] < new_lims[1]:\n",
    "            self.lims[1] = new_lims[1]\n",
    "\n",
    "    def output(self):\n",
    "        return self.lims\n",
    "    \n",
    "    \n",
    "# find 2D subplot index based on a numerical incremented index (ie. idx=3 would be (2,1) for a 2x2 subplot figure)     \n",
    "def subplot_loc(idx, num_rows, num_col):\n",
    "    if num_rows == 1:\n",
    "        subplot_index = idx\n",
    "    else:\n",
    "        subplot_index = np.unravel_index(idx, (num_rows, int(num_col))) # turn int index to a tuple of array coordinates\n",
    "    return subplot_index\n",
    "\n",
    "# calculate all the color limits for heatmaps; useful for locking color limits across different heatmap subplots   \n",
    "def generate_clims(data_in, norm_type):\n",
    "    # get min and max for all data across conditions \n",
    "    clims_out = [np.nanmin(data_in), np.nanmax(data_in)]\n",
    "    if 'zscore' in norm_type: # if data are zscored, make limits symmetrical and centered at 0\n",
    "        clims_max = np.max(np.abs(clims_out)) # then we take the higher of the two magnitudes\n",
    "        clims_out = [-clims_max*0.5, clims_max*0.5] # and set it as the negative and positive limit for plotting\n",
    "    return clims_out\n",
    "\n",
    "def get_cmap(n, name='plasma'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "\n",
    "def is_all_nans(vector):\n",
    "    \"\"\"\n",
    "    checks if series or vector contains all nans; returns boolean. Used to identify and exclude all-nan rois\n",
    "    \"\"\"\n",
    "    if isinstance(vector, pd.Series):\n",
    "        vector = vector.values\n",
    "    return np.isnan(vector).all()\n",
    "\n",
    "# function for finding the index of the closest entry in an array to a provided value\n",
    "def find_nearest_idx(array, value):\n",
    "\n",
    "    if isinstance(array, pd.Series):\n",
    "        idx = (np.abs(array - value)).idxmin()\n",
    "        return idx, array.index.get_loc(idx), array[idx] # series index, 0-relative index, entry value\n",
    "    else:\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return idx, array[idx]\n",
    "\n",
    "    \n",
    "# function to find closest sample when a time occurs in a time vector\n",
    "tvec2samp = lambda tvec, time: np.argmin(np.abs(tvec - time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "USER-DEFINED VARIABLES\n",
    "\"\"\"\n",
    "\n",
    "def define_params(method = 'single'):\n",
    "    \n",
    "    fparams = {}\n",
    "    \n",
    "    if method == 'single':\n",
    "        \n",
    "        fparams['fname_signal'] = 'VJ_OFCVTA_7_260_D6_neuropil_corrected_signals_15_50_beta_0.8.npy'   # \n",
    "        fparams['fname_events'] = 'event_times_VJ_OFCVTA_7_260_D6_trained.csv'\n",
    "        # fdir signifies to the root path of the data. Currently, the abspath phrase points to sample data from the repo.\n",
    "        # To specify a path that is on your local computer, use this string format: r'your_root_path', where you should copy/paste\n",
    "        # your path between the single quotes (important to keep the r to render as a complete raw string). See example below:\n",
    "        # r'C:\\Users\\stuberadmin\\Documents\\GitHub\\NAPE_imaging_postprocess\\napeca_post\\sample_data' \n",
    "        fparams['fdir'] = os.path.abspath('./sample_data/VJ_OFCVTA_7_260_D6') \n",
    "        fparams['fname'] = os.path.split(fparams['fdir'])[1]\n",
    "        fparams['flag_close_figs_after_save'] = True\n",
    "        fparams['flag_save_figs'] = True\n",
    "        \n",
    "        # set the sampling rate\n",
    "        fparams['fs'] = 5 # this gets overwritten by json fs variable (if it exists) that is saved in preprocessing\n",
    "        json_fpath = os.path.join(fparams['fdir'], fparams['fname']+\".json\")\n",
    "        if os.path.exists(json_fpath):\n",
    "            json_data = utils.open_json(json_fpath)\n",
    "            if 'fs' in json_data:\n",
    "                fparams['fs'] = json_data['fs']\n",
    "\n",
    "        # set to None if want to include all conditions from behav data; \n",
    "        # otherwise, set to list of conditions, eg. ['plus', 'minus']\n",
    "        fparams['selected_conditions'] = None \n",
    "        \n",
    "        # trial windowing and normalization\n",
    "        fparams['trial_start_end'] = [-2, 8] # [start, end] times (in seconds) included in the visualization \n",
    "        fparams['flag_normalization'] = 'zscore' # options: 'zscore', None\n",
    "        fparams['baseline_end'] = -0.2 # baseline epoch end time (in seconds) for performing baseline normalization\n",
    "        fparams['event_dur'] = 2 # duration of stim/event in seconds; displays a line below main plot indicating event duration\n",
    "        fparams['event_sort_analysis_win'] = [0, 5] # time window (in seconds)\n",
    "        \n",
    "        # session info\n",
    "        fparams['opto_blank_frame'] = False # if PMTs were blanked during stim, set stim times to nan (instead of 0)\n",
    "\n",
    "        # ROI sorting; if flag_sort_rois is set to True, ROIs are sorted by activity in the fparams['event_sort_analysis_win'] window\n",
    "        fparams['flag_sort_rois'] = True\n",
    "        if fparams['flag_sort_rois']:\n",
    "            \n",
    "            fparams['user_sort_method'] = 'max_value' # peak_time or max_value\n",
    "            fparams['roi_sort_cond'] = 'plus' # for roi-resolved heatmaps, which condition to sort ROIs by\n",
    "            \n",
    "        # errorbar and saving figures\n",
    "        fparams['flag_roi_trial_avg_errbar'] = True # toggle to show error bar on roi- and trial-averaged traces\n",
    "        fparams['flag_trial_avg_errbar'] = True # toggle to show error bars on the trial-avg traces\n",
    "        fparams['interesting_rois'] = [] #[ 0, 1, 2, 23, 22, 11, 9, 5, 6, 7, 3, 4, 8, 12, 14, 15, 16, 17] # [35, 30, 20, 4] #\n",
    "    \n",
    "    elif method == 'f2a': # if string is empty, load predefined list of files in files_to_analyze_event\n",
    "\n",
    "        fparams = files_to_analyze_event.define_fparams()\n",
    "\n",
    "    elif method == 'root_dir':\n",
    "        \n",
    "        pass\n",
    "\n",
    "    with open(os.path.join(fparams['fdir'], 'event_analysis_fparam.json'), 'w') as fp:\n",
    "        json.dump(fparams, fp)\n",
    "    \n",
    "    return fparams\n",
    "\n",
    "fparams = define_params(method = 'single') # options are 'single', 'f2a', 'root_dir'\n",
    "\n",
    "if 'zscore' in fparams['flag_normalization']:\n",
    "    data_trial_resolved_key = 'zdata'\n",
    "    data_trial_avg_key = 'ztrial_avg_data'\n",
    "    cmap_ = None\n",
    "    ylabel = 'Z-score Activity'\n",
    "else:\n",
    "    data_trial_resolved_key = 'data'\n",
    "    data_trial_avg_key = 'trial_avg_data'\n",
    "    cmap_ = 'inferno'\n",
    "    ylabel = 'Activity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# declare paths\n",
    "def define_paths(dict_vars, fparams):\n",
    "    dict_vars['signals_fpath'] = os.path.join(fparams['fdir'], fparams['fname_signal'])\n",
    "    dict_vars['events_file_path'] = os.path.join(fparams['fdir'], fparams['fname_events'])\n",
    "\n",
    "    dict_vars['save_dir']= os.path.join(fparams['fdir'], 'event_rel_analysis')\n",
    "    utils.check_exist_dir(dict_vars['save_dir']); # make the save directory\n",
    "\n",
    "    return dict_vars\n",
    "\n",
    "def make_timing_info(dict_vars, fparams):\n",
    "    ### create variables that reference samples and times for slicing and plotting the data\n",
    "    trial_start_end_sec = np.array(fparams['trial_start_end']) # trial windowing in seconds relative to ttl-onset/trial-onset, in seconds\n",
    "    baseline_start_end_sec = np.array([trial_start_end_sec[0], fparams['baseline_end']])\n",
    "\n",
    "    # convert times to samples and get sample vector for the trial \n",
    "    dict_analysis_vars['trial_begEnd_samp'] = trial_start_end_sec*fparams['fs'] # turn trial start/end times to samples\n",
    "    trial_svec = np.arange(dict_vars['trial_begEnd_samp'][0], dict_vars['trial_begEnd_samp'][1])\n",
    "    # and for baseline period\n",
    "    dict_vars['baseline_begEnd_samp'] = baseline_start_end_sec*fparams['fs']\n",
    "    dict_vars['baseline_svec'] = (np.arange(dict_vars['baseline_begEnd_samp'][0], dict_vars['baseline_begEnd_samp'][1]+1, 1) - dict_vars['baseline_begEnd_samp'][0]).astype('int')\n",
    "\n",
    "    # calculate time vector for plot x axes\n",
    "    num_samples_trial = len( trial_svec )\n",
    "    dict_vars['tvec'] = np.round(np.linspace(trial_start_end_sec[0], trial_start_end_sec[1], num_samples_trial+1), 2)\n",
    "\n",
    "    # find samples and calculations for time 0 for plotting\n",
    "    dict_vars['t0_sample'] = utils.get_tvec_sample(dict_vars['tvec'], 0) # grabs the sample index of a given time from a vector of times\n",
    "    dict_vars['event_end_sample'] = int(np.round(dict_vars['t0_sample']+fparams['event_dur']*fparams['fs']))\n",
    "    # event_bound_ratio : fraction of total samples for event start and end. Used for mapping which samples to plot green line indicating event duration\n",
    "    dict_vars['event_bound_ratio'] = [(dict_vars['t0_sample'])/num_samples_trial , dict_vars['event_end_sample']/num_samples_trial] # fraction of total samples for event start and end; only used for plotting line indicating event duration\n",
    "\n",
    "    return dict_vars\n",
    "\n",
    "def load_signals(dict_vars, fparams):\n",
    "    # requires define_paths method to be run first \n",
    "    signals = utils.load_signals(dict_vars['signals_fpath'])\n",
    "\n",
    "    dict_vars['num_rois'] = signals.shape[0]\n",
    "    dict_vars['all_nan_rois'] = np.where(np.apply_along_axis(is_all_nans, 1, signals)) # find rois with activity as all nans\n",
    "\n",
    "    # if opto stim frames were detected in preprocessing, set these frames to be NaN (b/c of stim artifact)\n",
    "    if fparams['opto_blank_frame']:\n",
    "        try:\n",
    "            glob_stim_files = glob.glob(os.path.join(fparams['fdir'], \"{}*_stimmed_frames.pkl\".format(fparams['fname'])))\n",
    "            stim_frames = pickle.load( open( glob_stim_files[0], \"rb\" ) )\n",
    "            signals[:,stim_frames['samples']] = None # blank out stimmed frames\n",
    "            flag_stim = True\n",
    "            print('Detected stim data; replaced stim samples with NaNs')\n",
    "        except:\n",
    "            flag_stim = False\n",
    "            print('Note: No stim preprocessed meta data detected.')\n",
    "\n",
    "    dict_vars['signals'] = signals\n",
    "\n",
    "    return dict_vars\n",
    "\n",
    "def load_behav(dict_vars, fparams):\n",
    "    ### load behavioral data and trial info\n",
    "    # requires define_paths method to be run first \n",
    "\n",
    "    glob_event_files = glob.glob(dict_vars['events_file_path']) # look for a file in specified directory\n",
    "    if not glob_event_files:\n",
    "        print('{} not detected. Please check if path is correct.'.format(dict_vars['events_file_path']))\n",
    "    if 'csv' in glob_event_files[0]:\n",
    "        event_times = utils.df_to_dict(glob_event_files[0])\n",
    "    elif 'pkl' in glob_event_files[0]:\n",
    "        event_times = pickle.load( open( glob_event_files[0], \"rb\" ), fix_imports=True, encoding='latin1' ) # latin1 b/c original pickle made in python 2\n",
    "    dict_vars['event_frames'] = utils.dict_samples_to_time(event_times, fparams['fs'])\n",
    "\n",
    "    # identify conditions to analyze\n",
    "    all_conditions = dict_vars['event_frames'].keys()\n",
    "    conditions = [ condition for condition in all_conditions if len(dict_vars['event_frames'][condition]) > 0 ] # keep conditions that have events\n",
    "\n",
    "    conditions.sort()\n",
    "    if fparams['selected_conditions']:\n",
    "        conditions = fparams['selected_conditions']\n",
    "    dict_vars['conditions'] = conditions\n",
    "    dict_vars['cmap_lines'] = get_cmap(len(conditions)) # colors for plotting lines for each condition\n",
    "\n",
    "    return dict_vars\n",
    "\n",
    "def set_fontsizes(dict_vars):\n",
    "    # declare some fixed constant variables\n",
    "    dict_vars['axis_label_size'] = 15\n",
    "    dict_vars['tick_font_size'] = 14 \n",
    "    return dict_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_trial_heatmap(fig, ax, data_in, tvec, event_bound_ratio, clims, title, \n",
    "                          subplot_index, cmap_='inferno', save_fig = False, axis_label_size=15, tick_font_size=14):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data_in : np.array with dimensions trials x samples\n",
    "        \n",
    "    \n",
    "    Prep information about specific condition (each loop) and plot heatmap\n",
    "        1) x/y label tick values\n",
    "        2) x/y labels\n",
    "        3) grab specific condition's data\n",
    "        4) plot data (using utils function)\n",
    "        5) plot meta data lines (eg. 0-time line, event duration line)\n",
    "\n",
    "    event_bound_ratio : list of two entries\n",
    "        where entries are fraction of total samples for event start and end. Used for mapping which samples to plot green line \n",
    "        indicating event duration\n",
    "    \"\"\"\n",
    "\n",
    "    # set imshow extent to replace x and y axis ticks/labels\n",
    "    plot_extent = [tvec[0], tvec[-1], data_in.shape[0], 0] # [x min, x max, y min, ymax]\n",
    "\n",
    "    # prep labels; plot x and y labels for first subplot\n",
    "    if subplot_index == (0, 0) or subplot_index == 0 :\n",
    "        ax[subplot_index].set_ylabel('Trial', fontsize=axis_label_size)\n",
    "        ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "    ax[subplot_index].tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "\n",
    "    # prep the data\n",
    "    to_plot = np.squeeze(data_in) \n",
    "    if data_in.shape[0] == 1: # accomodates single trial data\n",
    "        to_plot = to_plot[np.newaxis, :]\n",
    "\n",
    "    # plot the data\n",
    "    im = utils.subplot_heatmap(ax[subplot_index], title, to_plot, cmap=cmap_, clims=clims, extent_=plot_extent)\n",
    "\n",
    "    # add meta data lines\n",
    "    ax[subplot_index].axvline(0, color='0.5', alpha=1) # plot vertical line for time zero\n",
    "    # plots green horizontal line indicating event duration\n",
    "    ax[subplot_index].annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                               xytext=(event_bound_ratio[1], -0.01), \n",
    "                               arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "\n",
    "    cbar = fig.colorbar(im, ax = ax[subplot_index], shrink = 0.5)\n",
    "    cbar.ax.set_ylabel(ylabel, fontsize = axis_label_size)\n",
    "\n",
    "    \n",
    "def plot_trial_heatmap_traces(dict_vars, fparams, data_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a figure per ROI/channel\n",
    "    Each figure consists of n heatmap panels of trial activity centered on an event where n is the number of event types/conditions.\n",
    "    The last panel of the figure contains trial-averaged traces for all conditions\n",
    "    \"\"\"\n",
    "    \n",
    "    num_subplots = len(dict_vars['conditions']) + 1 # plus one for trial-avg traces\n",
    "    n_columns = np.min([num_subplots, 4.0])\n",
    "    n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "    for iROI in range(dict_vars['num_rois']):\n",
    "\n",
    "        # calculate color limits. This is outside of heatmap function b/c want lims across conditions\n",
    "        # loop through each condition's data and flatten before concatenating values\n",
    "        roi_clims = generate_clims(np.concatenate([data_dict[cond][data_trial_resolved_key][:, iROI, :].flatten() for cond in dict_vars['conditions']]), \n",
    "                                   fparams['flag_normalization'])\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), \n",
    "                               figsize=(n_columns*4, n_rows*3),\n",
    "                               constrained_layout=True)\n",
    "\n",
    "        ### Plot heatmaps for each condition\n",
    "        for idx_cond, cond in enumerate(dict_vars['conditions']):\n",
    "\n",
    "            subplot_index = subplot_loc(idx_cond, n_rows, n_columns) # determine subplot location index\n",
    "            data_to_plot = data_dict[cond][data_trial_resolved_key][:, iROI, :]\n",
    "            title = 'ROI {}; {}'.format(str(iROI), cond)\n",
    "\n",
    "            subplot_trial_heatmap(fig, ax, data_to_plot, dict_vars['tvec'], dict_vars['event_bound_ratio'], \n",
    "                                  roi_clims, title, subplot_index, cmap_, save_fig=False, \n",
    "                                  axis_label_size=dict_vars['axis_label_size'], tick_font_size=dict_vars['tick_font_size'])\n",
    "\n",
    "        ### plot last subplot of trial-avg traces\n",
    "\n",
    "        # determine subplot location index\n",
    "        subplot_index = subplot_loc(num_subplots-1, n_rows, n_columns)\n",
    "\n",
    "        for cond in dict_analysis_vars['conditions']:\n",
    "\n",
    "            # prep data to plot\n",
    "            num_trials = data_dict[cond]['num_trials']\n",
    "            to_plot = np.nanmean(data_dict[cond][data_trial_resolved_key][:,iROI,:], axis=0)\n",
    "            to_plot_err = np.nanstd(data_dict[cond][data_trial_resolved_key][:,iROI,:], axis=0)/np.sqrt(num_trials)\n",
    "\n",
    "            # plot trace\n",
    "            ax[subplot_index].plot(dict_vars['tvec'], to_plot)\n",
    "            if fparams['opto_blank_frame']: \n",
    "                ax[subplot_index].plot(tvec[dict_vars['t0_sample']:dict_vars['event_end_sample']], \n",
    "                                       to_plot[dict_vars['t0_sample']:dict_vars['event_end_sample']], marker='.', color='g')\n",
    "            # plot shaded error\n",
    "            if fparams['flag_trial_avg_errbar']:\n",
    "                ax[subplot_index].fill_between(dict_vars['tvec'], to_plot - to_plot_err, to_plot + to_plot_err,\n",
    "                             alpha=0.5) # this plots the shaded error bar\n",
    "\n",
    "        # plot x, y labels, and legend\n",
    "        ax[subplot_index].set_ylabel(ylabel, fontsize=dict_vars['axis_label_size'])\n",
    "        ax[subplot_index].set_xlabel('Time [s]', fontsize=dict_vars['axis_label_size'])\n",
    "        ax[subplot_index].set_title('ROI # {}; Trial-avg'.format(str(iROI)), fontsize=dict_vars['axis_label_size'])\n",
    "        ax[subplot_index].legend(dict_vars['conditions'])\n",
    "        ax[subplot_index].autoscale(enable=True, axis='both', tight=True)\n",
    "        ax[subplot_index].axvline(0, color='0.5', alpha=0.65) # plot vertical line for time zero\n",
    "        ax[subplot_index].annotate('', xy=(dict_vars['event_bound_ratio'][0], -0.01), xycoords='axes fraction', \n",
    "                                       xytext=(dict_vars['event_bound_ratio'][1], -0.01), \n",
    "                                       arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "        ax[subplot_index].tick_params(axis = 'both', which = 'major', labelsize = dict_vars['tick_font_size'])\n",
    "\n",
    "        for a in ax.flat[num_subplots:]:\n",
    "            a.axis('off')\n",
    "\n",
    "        if fparams['flag_save_figs']:\n",
    "            fig.savefig( os.path.join(dict_vars['save_dir'],'roi_{}_activity.png'.format(str(iROI))) ); \n",
    "            fig.savefig( os.path.join(dict_vars['save_dir'],'roi_{}_activity.pdf'.format(str(iROI))) );\n",
    "\n",
    "        if fparams['flag_close_figs_after_save']:\n",
    "            plt.close(fig)\n",
    "            \n",
    "            \n",
    "def sort_heatmap_peaks(data, tvec, sort_epoch_start_time, sort_epoch_end_time, sort_method = 'peak_time'):\n",
    "    # function to sort ROIs based on activity in certain epoch\n",
    "    \n",
    "    # find start/end samples for epoch\n",
    "    sort_epoch_start_samp = tvec2samp(tvec, sort_epoch_start_time)\n",
    "    sort_epoch_end_samp = tvec2samp(tvec, sort_epoch_end_time)\n",
    "    \n",
    "    if sort_method == 'peak_time':\n",
    "        epoch_peak_samp = np.argmax(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.argsort(epoch_peak_samp)\n",
    "    elif sort_method == 'max_value':\n",
    " \n",
    "        time_max = np.nanmax(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.argsort(time_max)[::-1]\n",
    "\n",
    "    return final_sorting\n",
    "\n",
    "\n",
    "\n",
    "def sort_rois(dict_vars, fparams, data_trial_avg_key):\n",
    "\n",
    "    if fparams['flag_sort_rois']: # if flag is true, sort rois by average activity in specific window\n",
    "        if not fparams['roi_sort_cond']: # if no condition to sort by specified, use first condition\n",
    "            fparams['roi_sort_cond'] = data_dict.keys()[0]\n",
    "        if not fparams['roi_sort_cond'] in data_dict.keys():\n",
    "            sorted_roi_order = range(dict_vars['num_rois'])\n",
    "            interesting_rois = fparams['interesting_rois']\n",
    "            print('Specified condition to sort by doesn\\'t exist! ROIs are in default sorting.')\n",
    "        else: # if sorting condition is valid, sort based on activity\n",
    "            # returns new order of rois sorted using the data and method supplied in the specified window\n",
    "            sorted_roi_order = sort_heatmap_peaks(data_dict[fparams['roi_sort_cond']][data_trial_avg_key], dict_vars['tvec'], \n",
    "                               sort_epoch_start_time=0, \n",
    "                               sort_epoch_end_time = fparams['trial_start_end'][-1], \n",
    "                               sort_method = fparams['user_sort_method'])\n",
    "            # finds corresponding interesting roi (roi's to mark with an arrow) order after sorting\n",
    "            interesting_rois = np.in1d(sorted_roi_order, fparams['interesting_rois']).nonzero()[0] \n",
    "    else:\n",
    "        sorted_roi_order = range(dict_vars['num_rois'])\n",
    "        interesting_rois = fparams['interesting_rois']\n",
    "\n",
    "    # get rid of ROIs that have all NaN's in data\n",
    "    if not dict_vars['all_nan_rois'][0].size == 0:\n",
    "        set_diff_keep_order = lambda main_list, remove_list : [i for i in main_list if i not in remove_list]\n",
    "        sorted_roi_order = set_diff_keep_order(dict_vars['sorted_roi_order'], dict_vars['all_nan_rois'])\n",
    "        interesting_rois = [i for i in fparams['interesting_rois'] if i not in dict_vars['all_nan_rois']]\n",
    "        print(f'Removed {str(len(remove_list))} ROIs with NaN data')\n",
    "    \n",
    "    # save sorted roi order\n",
    "    roi_order_path = os.path.join(fparams['fdir'], fparams['fname'] + '_roi_order.pkl')\n",
    "    with open(roi_order_path, 'wb') as handle:\n",
    "         pickle.dump(sorted_roi_order, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    dict_vars['sorted_roi_order'] = sorted_roi_order\n",
    "    dict_vars['interesting_rois'] = interesting_rois            \n",
    "    \n",
    "    return dict_vars\n",
    "\n",
    "\n",
    "def plot_trial_avg_heatmap(dict_vars, data_in, cmap, clims, sorted_roi_order=None, \n",
    "                           rois_oi=None, save_fig=False, axis_label_size=15, tick_font_size=14):\n",
    "    \n",
    "    \"\"\"\n",
    "    Technically doesn't need to remove all_nan_rois b/c of nanmean calculations\n",
    "    \"\"\"\n",
    "    \n",
    "    num_subplots = len(dict_vars['conditions'])\n",
    "    n_columns = np.min([num_subplots, 3.0])\n",
    "    n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "    # set imshow extent to replace x and y axis ticks/labels (replace samples with time)\n",
    "    plot_extent = [dict_vars['tvec'][0], dict_vars['tvec'][-1], dict_vars['num_rois'], 0 ]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), figsize = (n_columns*5, n_rows*4))\n",
    "    if not isinstance(ax,np.ndarray): # this is here to make the code below compatible with indexing a single subplot object\n",
    "        ax = [ax]\n",
    "\n",
    "    for idx, cond in enumerate(dict_vars['conditions']):\n",
    "\n",
    "        # determine subplot location index\n",
    "        if n_rows == 1:\n",
    "            subplot_index = idx\n",
    "        else:\n",
    "            subplot_index = np.unravel_index(idx, (n_rows, int(n_columns))) # turn int index to a tuple of array coordinates\n",
    "\n",
    "        # prep labels; plot x and y labels for first subplot\n",
    "        if subplot_index == (0, 0) or subplot_index == 0 :\n",
    "            ax[subplot_index].set_ylabel('ROI #', fontsize=axis_label_size)\n",
    "            ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "        ax[subplot_index].tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "        \n",
    "        # plot the data\n",
    "        if sorted_roi_order is not None:\n",
    "            roi_order = sorted_roi_order\n",
    "        else:\n",
    "            roi_order = slice(0, dict_vars['num_rois'])\n",
    "        to_plot = data_in[cond][data_trial_avg_key][roi_order,:] # \n",
    "\n",
    "        im = utils.subplot_heatmap(ax[subplot_index], cond, to_plot, cmap=cmap_, clims=clims, extent_=plot_extent)\n",
    "        ax[subplot_index].axvline(0, color='k', alpha=0.3) # plot vertical line for time zero\n",
    "        ax[subplot_index].annotate('', xy=(dict_vars['event_bound_ratio'][0], -0.01), xycoords='axes fraction', \n",
    "                                       xytext=(dict_vars['event_bound_ratio'][1], -0.01), \n",
    "                                       arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "        if rois_oi is not None:\n",
    "            for ROI_OI in rois_oi:\n",
    "                ax[subplot_index].annotate('', xy=(1.005, 1-(ROI_OI/dict_vars['num_rois'])-0.015), xycoords='axes fraction', \n",
    "                                           xytext=(1.06, 1-(ROI_OI/dict_vars['num_rois'])-0.015), \n",
    "                                           arrowprops=dict(arrowstyle=\"->\", color='k'))\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    cbar = fig.colorbar(im, ax = ax, shrink = 0.7)\n",
    "    cbar.ax.set_ylabel(ylabel, fontsize=13)\n",
    "    \n",
    "    # hide empty subplot\n",
    "    for a in ax.flat[num_subplots:]:\n",
    "        a.axis('off')\n",
    "    \n",
    "    if save_fig:\n",
    "        fig.savefig(os.path.join(dict_vars['save_dir'],'trial_avg_heatmap.png')); \n",
    "        fig.savefig(os.path.join(dict_vars['save_dir'],'trial_avg_heatmap.pdf'));\n",
    "        \n",
    "        \n",
    "def plot_trial_roi_avg_traces(dict_vars, fparams, data_trial_resolved_key, axis_label_size=15, tick_font_size=14):\n",
    "\n",
    "    line_shades = []\n",
    "    fig, axs = plt.subplots(1,1, figsize = (10,6))\n",
    "    for idx, cond in enumerate(dict_vars['conditions']):\n",
    "        line_color = dict_vars['cmap_lines'](idx)\n",
    "        # first trial avg the data\n",
    "        trial_avg = np.nanmean(data_dict[cond][data_trial_resolved_key], axis=0)\n",
    "\n",
    "        # z-score trial-avg data for each respective ROI\n",
    "        # apply zscore function to each row of data\n",
    "        app_axis = 1 \n",
    "        zscore_trial_avg = np.apply_along_axis(utils.zscore_, app_axis, trial_avg, dict_vars['baseline_svec'])\n",
    "\n",
    "        # take avg/std across ROIs\n",
    "        zscore_roi_trial_avg = np.nanmean(zscore_trial_avg, axis=0)\n",
    "        zscore_roi_trial_std = np.nanstd(zscore_trial_avg, axis=0)\n",
    "\n",
    "        to_plot = np.squeeze(zscore_roi_trial_avg)\n",
    "        to_plot_err = np.squeeze(zscore_roi_trial_std)/np.sqrt(dict_vars['num_rois'])\n",
    "\n",
    "        axs.plot(dict_vars['tvec'], to_plot, color=line_color)\n",
    "        if fparams['opto_blank_frame']:\n",
    "            line = axs.plot(dict_vars['tvec'][dict_vars['t0_sample']:dict_vars['event_end_sample']], \n",
    "                                 to_plot[dict_vars['t0_sample']:dict_vars['event_end_sample']], marker='.', color=line_color)\n",
    "        else:\n",
    "            line = axs.plot(dict_vars['tvec'][dict_vars['t0_sample']:dict_vars['event_end_sample']], \n",
    "                                 to_plot[dict_vars['t0_sample']:dict_vars['event_end_sample']], color=line_color)\n",
    "\n",
    "        if fparams['flag_roi_trial_avg_errbar']:\n",
    "            shade = axs.fill_between(dict_vars['tvec'], to_plot - to_plot_err, to_plot + to_plot_err, color = line_color,\n",
    "                         alpha=0.2) # this plots the shaded error bar\n",
    "            line_shades.append((line[0],shade))\n",
    "\n",
    "    axs.set_ylabel(ylabel, fontsize=axis_label_size)\n",
    "    axs.set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "    axs.legend(dict_vars['conditions']);\n",
    "    axs.legend(line_shades, dict_vars['conditions'], fontsize=15)\n",
    "    axs.axvline(0, color='0.5', alpha=0.65) # plot vertical line for time zero\n",
    "    axs.annotate('', xy=(dict_vars['event_bound_ratio'][0], -0.01), xycoords='axes fraction', \n",
    "                                   xytext=(dict_vars['event_bound_ratio'][1], -0.01), \n",
    "                                   arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "    axs.tick_params(axis = 'both', which = 'major', labelsize = tick_font_size+3)\n",
    "    axs.autoscale(enable=True, axis='both', tight=True)\n",
    "\n",
    "    #axs.set_ylim([-1.5, 10])\n",
    "\n",
    "    if fparams['flag_save_figs']:\n",
    "            fig.savefig(os.path.join(dict_vars['save_dir'],'roi_trial_avg_trace.png')); fig.savefig(os.path.join(dict_vars['save_dir'],'roi_trial_avg_trace.pdf'));\n",
    "\n",
    "            \n",
    "def stats_trial_roi_avg_traces(dict_vars, fparams, data_trial_resolved_key, axis_label_size=15, tick_font_size=14):\n",
    "\n",
    "    analysis_window = fparams['event_sort_analysis_win']\n",
    "    analysis_win_samps = [ find_nearest_idx(dict_vars['tvec'], time)[0] for time in analysis_window ]\n",
    "\n",
    "    to_plot = []\n",
    "    to_plot_err = []\n",
    "\n",
    "    fig, axs = plt.subplots(1,1, figsize = (5,5))\n",
    "    for idx, cond in enumerate(dict_vars['conditions']):\n",
    "        line_color = dict_vars['cmap_lines'](idx)\n",
    "        # first trial avg the data\n",
    "        trial_avg = np.nanmean(data_dict[cond][data_trial_resolved_key], axis=0)\n",
    "\n",
    "        # z-score trial-avg data for each respective ROI\n",
    "        # apply zscore function to each row of data\n",
    "        apply_axis = 1 \n",
    "        zscore_trial_avg = np.apply_along_axis(utils.zscore_, apply_axis, trial_avg, dict_vars['baseline_svec'])\n",
    "\n",
    "        # take avg across time\n",
    "        zscore_trial_time_avg = np.nanmean(zscore_trial_avg[:,analysis_win_samps[0]:analysis_win_samps[1],:], axis=1)\n",
    "\n",
    "        # take avg/std across ROIs\n",
    "        zscore_roi_trial_time_avg = np.nanmean(zscore_trial_time_avg, axis=0)\n",
    "        zscore_roi_trial_time_std = np.nanstd(zscore_trial_time_avg, axis=0)\n",
    "\n",
    "        to_plot.append(zscore_roi_trial_time_avg[0])\n",
    "        to_plot_err.append(zscore_roi_trial_time_std[0]/np.sqrt(len(zscore_trial_time_avg)))\n",
    "\n",
    "    barlist = axs.bar(dict_vars['conditions'], to_plot, yerr=to_plot_err, align='center', alpha=0.5, ecolor='black', capsize=10 )\n",
    "    for idx in range(len(dict_vars['conditions'])):\n",
    "        barlist[idx].set_color(dict_vars['cmap_lines'](idx))\n",
    "    axs.set_ylabel('Normalized Fluorescence', fontsize=axis_label_size)\n",
    "    axs.set_title('ROI-, Trial-, Time-averaged Quant', fontsize=axis_label_size)\n",
    "    axs.yaxis.grid(True)\n",
    "    axs.tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "    axs.tick_params(axis = 'x', which = 'major', rotation = 45)\n",
    "    # Save the figure and show\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if fparams['flag_save_figs']:\n",
    "        fig.savefig(os.path.join(dict_vars['save_dir'],'roi_trial_time_avg_bar.png')); \n",
    "\n",
    "        fig.savefig(os.path.join(dict_vars['save_dir'],'roi_trial_time_avg_bar.pdf'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    \"\"\"\n",
    "    Declare and compute meta information, raw, data, and plotting info\n",
    "    \"\"\"\n",
    "    print('Prepping meta info')\n",
    "    dict_analysis_vars = {}\n",
    "    ### create variables that reference samples and times for slicing and plotting the data\n",
    "    dict_analysis_vars = define_paths(dict_analysis_vars, fparams)\n",
    "    dict_analysis_vars = make_timing_info(dict_analysis_vars, fparams)\n",
    "\n",
    "    ### load behavioral data and trial info\n",
    "    dict_analysis_vars = load_signals(dict_analysis_vars, fparams)\n",
    "    dict_analysis_vars = load_behav(dict_analysis_vars, fparams)\n",
    "\n",
    "    dict_analysis_vars = set_fontsizes(dict_analysis_vars)\n",
    "\n",
    "    \"\"\"\n",
    "    MAIN data processing function to extract event-centered data\n",
    "\n",
    "    extract and save trial data, \n",
    "    saved data are in the event_rel_analysis subfolder, a pickle file that contains the extracted trial data\n",
    "    \"\"\"\n",
    "    print('Extracting event-related data')\n",
    "    data_dict = utils.extract_trial_data(dict_analysis_vars, dict_analysis_vars['signals'], dict_analysis_vars['event_frames'], \n",
    "                                         dict_analysis_vars['conditions'], save_dir=dict_analysis_vars['save_dir'])\n",
    "\n",
    "    \"\"\"\n",
    "    ## Plot trial-resolved heatmap for each ROI\n",
    "    \"\"\"\n",
    "    print('Plotting trial heatmaps for each ROI')\n",
    "    plot_trial_heatmap_traces(dict_analysis_vars, fparams, data_dict)\n",
    "\n",
    "    \"\"\"\n",
    "    ## Plot trial-averaged heatmap of all ROIs\n",
    "    \"\"\"\n",
    "    print('Plotting trial-averaged heatmaps all ROI')\n",
    "    dict_analysis_vars = sort_rois(dict_analysis_vars, fparams, data_trial_avg_key) # sort rois based on activity\n",
    "\n",
    "    plot_trial_avg_heatmap(dict_analysis_vars, data_dict, cmap_,\n",
    "                           clims = generate_clims(np.concatenate([data_dict[cond][data_trial_avg_key].flatten() for cond in dict_analysis_vars['conditions']]), \n",
    "                                                  fparams['flag_normalization']),\n",
    "                           sorted_roi_order = dict_analysis_vars['sorted_roi_order'], \n",
    "                           rois_oi = dict_analysis_vars['interesting_rois'], \n",
    "                           save_fig = fparams['flag_save_figs'],\n",
    "                           axis_label_size=dict_analysis_vars['axis_label_size'], tick_font_size=dict_analysis_vars['tick_font_size'])\n",
    "\n",
    "    \"\"\"\n",
    "    ## Plot trial- and ROI-averaged traces\n",
    "    \"\"\"\n",
    "    print('Plotting trial- and ROI-averaged traces')\n",
    "    plot_trial_roi_avg_traces(dict_analysis_vars, fparams, data_trial_resolved_key,\n",
    "                              axis_label_size=dict_analysis_vars['axis_label_size'], \n",
    "                              tick_font_size=dict_analysis_vars['tick_font_size'])\n",
    "\n",
    "    \"\"\"\n",
    "    ### Quantification of roi-, trial-, time-averaged data\n",
    "    \"\"\"\n",
    "    print('Plotting quantification of trial- and ROI-averaged data')\n",
    "    stats_trial_roi_avg_traces(dict_analysis_vars, fparams, data_trial_resolved_key,\n",
    "                               axis_label_size=dict_analysis_vars['axis_label_size'], \n",
    "                               tick_font_size=dict_analysis_vars['tick_font_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
