{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f81037-20ca-4ef9-9a16-8f780f7a2823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#important for text to be detected when importing saved figures into illustrator\n",
    "matplotlib.rcParams['pdf.fonttype']=42\n",
    "matplotlib.rcParams['ps.fonttype']=42\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477a4e9-de9f-4505-ab61-2b7c6a45d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find closest sample when a time occurs in a time vector\n",
    "tvec2samp = lambda tvec, time: np.argmin(np.abs(tvec - time))\n",
    "\n",
    "# function to sort ROIs based on activity in certain epoch\n",
    "def sort_heatmap_peaks(data, tvec, sort_epoch_start_time, sort_epoch_end_time, sort_method = 'peak_time'):\n",
    "    \n",
    "    # find start/end samples for epoch\n",
    "    sort_epoch_start_samp = tvec2samp(tvec, sort_epoch_start_time)\n",
    "    sort_epoch_end_samp = tvec2samp(tvec, sort_epoch_end_time)\n",
    "    \n",
    "    if sort_method == 'peak_time':\n",
    "        epoch_peak_samp = np.argmax(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.argsort(epoch_peak_samp)\n",
    "    elif sort_method == 'max_value':\n",
    " \n",
    "        time_max = np.nanmax(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.argsort(time_max)[::-1]\n",
    "    elif sort_method == 'mean_value':\n",
    "        epoch_peak_samp = np.mean(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.flip(np.argsort(epoch_peak_samp))\n",
    "        \n",
    "    return final_sorting\n",
    "\n",
    "def is_all_nans(vector):\n",
    "    \"\"\"\n",
    "    checks if series or vector contains all nans; returns boolean. Used to identify and exclude all-nan rois\n",
    "    \"\"\"\n",
    "    if isinstance(vector, pd.Series):\n",
    "        vector = vector.values\n",
    "    return np.isnan(vector).all()\n",
    "\n",
    "# declare some fixed constant variables\n",
    "axis_label_size = 15\n",
    "tick_font_size = 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be13a5ed-2ef8-4822-b126-c1e9c334f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "USER-DEFINED VARIABLES\n",
    "\"\"\"\n",
    "\n",
    "def define_params(method = 'single'):\n",
    "    \n",
    "    fparams = {}\n",
    "    \n",
    "    if method == 'single':\n",
    "\n",
    "        # default sample data generously provided by Cat Zamorano\n",
    "        fparams['fname_signal'] = 'heatmap_slice_s2p_neuropil_corrected_signals.npy'   # \n",
    "        fparams['fname_events'] = 'heatmap_slice_events.csv' # can set to None if you want to plot the signals only\n",
    "        # fdir signifies to the root path of the data. Currently, the abspath phrase points to sample data from the repo.\n",
    "        # To specify a path that is on your local computer, use this string format: r'your_root_path', where you should copy/paste\n",
    "        # your path between the single quotes (important to keep the r to render as a complete raw string). See example below:\n",
    "        # r'C:\\Users\\stuberadmin\\Documents\\GitHub\\NAPE_imaging_postprocess\\napeca_post\\sample_data' \n",
    "        fparams['fdir'] = os.path.abspath('./sample_data/heatmap_slice')\n",
    "        fparams['fname'] = os.path.split(fparams['fdir'])[1]\n",
    "        fparams['flag_save_figs'] = False\n",
    "        fparams['flag_close_figs_after_save'] = False\n",
    "        \n",
    "        # set the sampling rate\n",
    "        fparams['fs'] = 0.46\n",
    "\n",
    "        # session info\n",
    "        fparams['opto_blank_frame'] = False # if PMTs were blanked during stim, set stim times to nan (instead of 0)\n",
    "        \n",
    "        # analysis and plotting arguments\n",
    "        fparams['num_rois'] = 'all' # set to 'all' if want to show all cells\n",
    "        fparams['selected_conditions'] = None # set to None if want to include all conditions from behav data\n",
    "        fparams['flag_normalization'] = 'zscore' # options: 'dff', 'zscore', 'dff_perc', None\n",
    "        fparams['baseline_epoch'] = [0, 60]\n",
    "        fparams['event_sort_analysis_win'] = [200, 400] # time window (in seconds) for sorting cells; list [start, end]\n",
    "        fparams['interesting_rois'] = []\n",
    "        \n",
    "        # ROI sorting; if flag_sort_rois is set to True, ROIs are sorted by activity in the fparams['event_sort_analysis_win'] window\n",
    "        fparams['flag_sort_rois'] = True\n",
    "        if fparams['flag_sort_rois']:\n",
    "            fparams['user_sort_method'] = 'mean_value' # peak_time, mean_value or max_value\n",
    "            fparams['roi_sort_cond'] = 'damgo' # for roi-resolved heatmaps, which condition to sort ROIs by\n",
    "            \n",
    "    elif method == 'f2a': # if string is empty, load predefined list of files in files_to_analyze_event\n",
    "\n",
    "        fparams = files_to_analyze_event.define_fparams()\n",
    "\n",
    "    elif method == 'root_dir':\n",
    "        \n",
    "        pass\n",
    "\n",
    "    return fparams\n",
    "\n",
    "fparams = define_params(method = 'single') # options are 'single', 'f2a', 'root_dir'\n",
    "\n",
    "cond_colors = ['b', 'c', 'r', 'm', 'g', 'y']\n",
    "\n",
    "if 'zscore' == fparams['flag_normalization']:\n",
    "    data_trial_resolved_key = 'zdata'\n",
    "    data_trial_avg_key = 'ztrial_avg_data'\n",
    "    cmap_ = None\n",
    "    ylabel = 'Z-score Activity'\n",
    "else:\n",
    "    data_trial_resolved_key = 'data'\n",
    "    data_trial_avg_key = 'trial_avg_data'\n",
    "    cmap_ = 'inferno'\n",
    "    ylabel = 'Activity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d69c7b-754c-40a3-9806-eb14f73c1828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define load and save paths\n",
    "fext = os.path.splitext(fparams['fname_signal'])[-1]\n",
    "signals_fpath = os.path.join(fparams['fdir'], fparams['fname_signal'])\n",
    "\n",
    "if fparams['fname_events']:\n",
    "    events_file_path = os.path.join(fparams['fdir'], fparams['fname_events'])\n",
    "\n",
    "save_dir = os.path.join(fparams['fdir'], 'event_rel_analysis')\n",
    "\n",
    "utils.check_exist_dir(save_dir); # make the save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca038a6-0e73-4087-b305-cf95a86f0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to normalize traces\n",
    "def calc_dff_percentile(activity_vec, perc=25):\n",
    "    perc_activity = np.percentile(activity_vec, perc)\n",
    "    return (activity_vec-perc_activity)/perc_activity\n",
    "\n",
    "def calc_zscore(data, baseline_samples):\n",
    "    mean_baseline = np.nanmean(data[..., baseline_samples])\n",
    "    std_baseline = np.nanstd(data[..., baseline_samples])\n",
    "    return (data-mean_baseline)/std_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4e4f2-407d-4381-a917-e12bf99dbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load time-series data\n",
    "signals = utils.load_signals(signals_fpath)\n",
    "all_nan_rois = np.where(np.apply_along_axis(is_all_nans, 1, signals)) # find rois with activity as all nans\n",
    "\n",
    "if fparams['opto_blank_frame']:\n",
    "    try:\n",
    "        glob_stim_files = glob.glob(os.path.join(fparams['fdir'], \"{}*_stimmed_frames.pkl\".format(fparams['fname'])))\n",
    "        stim_frames = pickle.load( open( glob_stim_files[0], \"rb\" ) )\n",
    "        signals[:,stim_frames['samples']] = None # blank out stimmed frames\n",
    "        flag_stim = True\n",
    "        print('Detected stim data; replaced stim samples with NaNs')\n",
    "    except:\n",
    "        flag_stim = False\n",
    "        print('Note: No stim preprocessed meta data detected.')\n",
    "\n",
    "if fparams['flag_normalization'] == 'dff':\n",
    "    signal_to_plot = np.apply_along_axis(utils.calc_dff, 1, signals)\n",
    "elif fparams['flag_normalization'] == 'dff_perc':\n",
    "    signal_to_plot = np.apply_along_axis(calc_dff_percentile, 1, signals)\n",
    "elif fparams['flag_normalization'] == 'zscore':\n",
    "    if fparams['baseline_epoch']:\n",
    "        baseline_edge_samples = np.array(fparams['baseline_epoch'])*fparams['fs']\n",
    "        signal_to_plot = np.apply_along_axis(calc_zscore, 1, signals, np.arange(baseline_edge_samples[0], baseline_edge_samples[1]).astype('int'))\n",
    "    else:\n",
    "        signal_to_plot = np.apply_along_axis(calc_zscore, 1, signals, np.arange(0, signals.shape[1]))\n",
    "else:\n",
    "    signal_to_plot = signals\n",
    "\n",
    "min_max = [list(min_max_tup) for min_max_tup in zip(np.min(signal_to_plot,axis=1), np.max(signal_to_plot,axis=1))]\n",
    "min_max_all = [np.min(signal_to_plot), np.max(signal_to_plot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26458c6-2996-4477-870d-2a9684620a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fparams['num_rois'] == 'all':\n",
    "    fparams['num_rois'] = signals.shape[0]\n",
    "\n",
    "total_session_time = signals.shape[1]/fparams['fs']\n",
    "tvec = np.round(np.linspace(0, total_session_time, signals.shape[1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa50f6cc-ac9a-4e7c-b5d8-eb91120fab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load behavioral data and trial info\n",
    "if fparams['fname_events']:\n",
    "\n",
    "    glob_event_files = glob.glob(events_file_path) # look for a file in specified directory\n",
    "    if not glob_event_files:\n",
    "        print(f'{events_file_path} not detected. Please check if path is correct.')\n",
    "    if 'csv' in glob_event_files[0]:\n",
    "        event_times = utils.df_to_dict(glob_event_files[0])\n",
    "    elif 'pkl' in glob_event_files[0]:\n",
    "        event_times = pickle.load( open( glob_event_files[0], \"rb\" ), fix_imports=True, encoding='latin1' ) # latin1 b/c original pickle made in python 2\n",
    "    event_frames = utils.dict_time_to_samples(event_times, fparams['fs'])\n",
    "\n",
    "\n",
    "    event_times = {}\n",
    "    if fparams['selected_conditions']:\n",
    "        conditions = fparams['selected_conditions'] \n",
    "    else:\n",
    "        conditions = event_frames.keys()\n",
    "    for cond in conditions: # convert event samples to time in seconds\n",
    "            event_times[cond] = (np.array(event_frames[cond])/fparams['fs']).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e487b-be02-440e-b12a-ae1240bb4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if flag is true, sort ROIs (usually by average fluorescence within analysis window)\n",
    "if fparams['flag_sort_rois']:\n",
    "    if not fparams['roi_sort_cond']: # if no condition to sort by specified, use first condition\n",
    "        fparams['roi_sort_cond'] = conditions[0]\n",
    "    if not fparams['roi_sort_cond'] in conditions:\n",
    "        sorted_roi_order = range(fparams['num_rois'])\n",
    "        interesting_rois = fparams['interesting_rois']\n",
    "        print('Specified condition to sort by doesn\\'t exist! ROIs are in default sorting.')\n",
    "    else:\n",
    "        # returns new order of rois sorted using the data and method supplied in the specified window\n",
    "        sorted_roi_order = sort_heatmap_peaks(signal_to_plot, tvec, \n",
    "                           sort_epoch_start_time=fparams['event_sort_analysis_win'][0], \n",
    "                           sort_epoch_end_time = fparams['event_sort_analysis_win'][1], \n",
    "                           sort_method = fparams['user_sort_method'])\n",
    "        # finds corresponding interesting roi (roi's to mark with an arrow) order after sorting\n",
    "        interesting_rois = np.in1d(sorted_roi_order, fparams['interesting_rois']).nonzero()[0] \n",
    "else:\n",
    "    sorted_roi_order = range(fparams['num_rois'])\n",
    "    interesting_rois = fparams['interesting_rois']\n",
    "\n",
    "if not all_nan_rois[0].size == 0:\n",
    "    set_diff_keep_order = lambda main_list, remove_list : [i for i in main_list if i not in remove_list]\n",
    "    sorted_roi_order = set_diff_keep_order(sorted_roi_order, all_nan_rois)\n",
    "    interesting_rois = [i for i in fparams['interesting_rois'] if i not in all_nan_rois]\n",
    "\n",
    "if sorted_roi_order is not None:\n",
    "    roi_order = sorted_roi_order\n",
    "else:\n",
    "    roi_order = slice(0, fparams['num_rois'])\n",
    "\n",
    "roi_order_path = os.path.join(fparams['fdir'], fparams['fname'] + '_roi_order.pkl')\n",
    "with open(roi_order_path, 'wb') as handle:\n",
    "     pickle.dump(sorted_roi_order, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083148f2-3faf-49e2-9c7a-764a6c67016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all the color limits for heatmaps; useful for locking color limits across different heatmap subplots   \n",
    "def generate_clims(data_in, norm_type, scaling=1):\n",
    "    # get min and max for all data across conditions \n",
    "    clims_out = [np.nanmin(data_in), np.nanmax(data_in)]\n",
    "    if 'zscore' == norm_type: # if data are zscored, make limits symmetrical and centered at 0\n",
    "        clims_max = np.max(np.abs(clims_out)) # then we take the higher of the two magnitudes\n",
    "        clims_out = [-clims_max*scaling, clims_max*scaling] # and set it as the negative and positive limit for plotting\n",
    "    return clims_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65625476-f0ec-46e3-954d-fa02282dda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set imshow extent to replace x and y axis ticks/labels (replace samples with time)\n",
    "plot_extent = [tvec[0], tvec[-1], fparams['num_rois'], 0 ]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (10,5))\n",
    "\n",
    "subplot_index = 0\n",
    "\n",
    "ax.set_ylabel('ROI #', fontsize=axis_label_size)\n",
    "ax.set_xlabel('Time (s)', fontsize=axis_label_size);\n",
    "ax.tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "\n",
    "# plot the data\n",
    "to_plot = signal_to_plot[roi_order,:] # \n",
    "\n",
    "im = utils.subplot_heatmap(ax, 'Whole-session Heatmap', to_plot, cmap=cmap_, clims=generate_clims(signal_to_plot, fparams['flag_normalization'], 0.5), extent_=plot_extent)\n",
    "\n",
    "for cond_idx, cond in enumerate(conditions): # convert event samples to time in seconds\n",
    "    for event_time in event_times[cond]:\n",
    "        ax.axvline(event_time, color=cond_colors[cond_idx], alpha=1, linewidth=2, linestyle=(0, (5, 5))) # plot vertical line for time zero\n",
    "\n",
    "plt.legend(conditions)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "cbar = fig.colorbar(im, ax = ax, shrink = 0.7)\n",
    "cbar.ax.set_ylabel(ylabel, fontsize=13)\n",
    "\n",
    "if fparams['flag_save_figs']:\n",
    "    fig.savefig(os.path.join(save_dir,'trial_avg_heatmap.png')); \n",
    "    fig.savefig(os.path.join(save_dir,'trial_avg_heatmap.pdf'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec06c42-9d39-42c0-9a7b-37712e49843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iROI in range(fparams['num_rois']):\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (10,5))\n",
    "\n",
    "    to_plot = signal_to_plot[roi_order[iROI],:] # \n",
    "    ax.plot(tvec, to_plot, label='_no_legend')\n",
    "\n",
    "    ax.set_title('ROI # {}'.format(str(iROI)), fontsize=axis_label_size)\n",
    "    ax.set_ylabel(ylabel, fontsize=axis_label_size)\n",
    "    ax.set_xlabel('Time (s)', fontsize=axis_label_size);\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "        \n",
    "    for cond_idx, cond in enumerate(conditions): # convert event samples to time in seconds\n",
    "        for event_time in event_times[cond]:\n",
    "            ax.axvline(event_time, color=cond_colors[cond_idx], alpha=1, linewidth=2, linestyle=(0, (5, 5)), label=cond) # plot vertical line for time zero\n",
    "\n",
    "    plt.legend()\n",
    "    plt.autoscale(enable=True, axis='both', tight=True)\n",
    "    plt.ylim(generate_clims(signal_to_plot, fparams['flag_normalization']))\n",
    "    \n",
    "    if fparams['flag_save_figs']:\n",
    "        fig.savefig( os.path.join(save_dir,'roi_{}_activity.png'.format(str(iROI))) ); \n",
    "        fig.savefig( os.path.join(save_dir,'roi_{}_activity.pdf'.format(str(iROI))) );\n",
    "    \n",
    "    if fparams['flag_close_figs_after_save']:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86667e2d-a626-4953-ae4d-3fcb5e0c24be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
